{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ae2782-57ea-48f0-b948-b412d0076ffc",
   "metadata": {
    "id": "f6ae2782-57ea-48f0-b948-b412d0076ffc"
   },
   "source": [
    "# Deep Reinforcement Learning Laboratory\n",
    "\n",
    "In this laboratory session we will work on getting more advanced versions of Deep Reinforcement Learning algorithms up and running. Deep Reinforcement Learning is **hard**, and getting agents to stably train can be frustrating and requires quite a bit of subtlety in analysis of intermediate results. We will start by refactoring (a bit) my implementation of `REINFORCE` on the [Cartpole environment](https://gymnasium.farama.org/environments/classic_control/cart_pole/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadaf0c-f9b2-4680-8456-0eadb5eb8c2f",
   "metadata": {
    "id": "3fadaf0c-f9b2-4680-8456-0eadb5eb8c2f"
   },
   "source": [
    "## Exercise 1: Improving my `REINFORCE` Implementation (warm up)\n",
    "\n",
    "In this exercise we will refactor a bit and improve some aspects of my `REINFORCE` implementation.\n",
    "\n",
    "**First Things First**: Spend some time playing with the environment to make sure you understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241e9bdc-7aa9-4a12-a57f-088fdc87eab6",
   "metadata": {
    "id": "241e9bdc-7aa9-4a12-a57f-088fdc87eab6",
    "outputId": "0c82dc78-2f7c-4642-c04c-b2fc97fde729"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: niccolo-arati (dla-labs). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard imports.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Plus one non standard one -- we need this to sample from policies.\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "#Tracking experiments\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd2dd9d-a60b-4892-878f-d83f64ac5f63",
   "metadata": {
    "id": "cbd2dd9d-a60b-4892-878f-d83f64ac5f63",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def temperature_scaled_softmax(logits, temperature):\n",
    "    logits = logits / temperature\n",
    "    return F.softmax(logits, dim=-1)\n",
    "\n",
    "# A simple, but generic, policy network with one hidden layer.\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, env, inner_size = 128, T=1.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(env.observation_space.shape[0], inner_size)\n",
    "        self.fc2 = nn.Linear(inner_size, env.action_space.n)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.temperature = T\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = F.relu(self.fc1(s))\n",
    "        s = temperature_scaled_softmax(self.fc2(s), self.temperature)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae31dce-be71-4a86-95fd-1af902f026b8",
   "metadata": {
    "id": "0ae31dce-be71-4a86-95fd-1af902f026b8"
   },
   "source": [
    "**Next Things Next**: Now get your `REINFORCE` implementation working on the environment. You can import my (probably buggy and definitely inefficient) implementation here. Or even better, refactor an implementation into a separate package from which you can `import` the stuff you need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad8b148-6268-408c-bf20-a75d770746c0",
   "metadata": {
    "id": "6ad8b148-6268-408c-bf20-a75d770746c0"
   },
   "outputs": [],
   "source": [
    "class Reinforce:\n",
    "    def __init__(self, policy, env, env_render=None, gamma=0.99, num_episodes=10, lr=1e-2,\n",
    "                 max_len = 500, N = 100):\n",
    "        self.policy = policy\n",
    "        self.environment = env\n",
    "        self.env_render = env_render\n",
    "        self.gamma = gamma\n",
    "        self.num_episodes = num_episodes\n",
    "        self.learning_rate = lr\n",
    "        self.max_len = max_len #per gli episodi\n",
    "        self.N = N\n",
    "\n",
    "    # Given an environment, observation, and policy, sample from pi(a | obs). Returns the\n",
    "    # selected action and the log probability of that action (needed for policy gradient).\n",
    "    def select_action(self, obs):\n",
    "        dist = Categorical(self.policy(obs))\n",
    "        action = dist.sample() \n",
    "        log_prob = dist.log_prob(action)\n",
    "        return (action.item(), log_prob.reshape(1))\n",
    "\n",
    "    def select_max_action(self, obs):\n",
    "        probs = self.policy(obs)\n",
    "        action = torch.argmax(probs)\n",
    "        log_prob = torch.log(torch.max(probs))\n",
    "        return(action.item(), log_prob.reshape(1))\n",
    "\n",
    "    # Utility to compute the discounted total reward. Torch doesn't like flipped arrays, so we need to\n",
    "    # .copy() the final numpy array. There's probably a better way to do this.\n",
    "    def compute_returns(self, rewards):\n",
    "        return np.flip(np.cumsum([self.gamma**(i+1)*r for (i, r) in enumerate(rewards)][::-1]), 0).copy()\n",
    "\n",
    "    def setEnvRender(self, env_render):\n",
    "        self.env_render = env_render\n",
    "    \n",
    "    def setPolicy(self, policy):\n",
    "        self.policy = policy\n",
    "\n",
    "    # Given an environment and a policy, run it up to the maximum number of steps.\n",
    "    def run_episode(self, display=False, test=False):\n",
    "        # Collect just about everything.\n",
    "        observations = []\n",
    "        actions = []\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        env = self.environment\n",
    "        if display:\n",
    "            env = self.env_render\n",
    "\n",
    "        # Reset the environment and start the episode.\n",
    "        (obs, info) = env.reset()\n",
    "        for i in range(self.max_len):\n",
    "            # Get the current observation, run the policy and select an action.\n",
    "            obs = torch.tensor(obs)\n",
    "            if test:\n",
    "                (action, log_prob) = self.select_max_action(obs)\n",
    "            else:\n",
    "                (action, log_prob) = self.select_action(obs)\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            log_probs.append(log_prob)\n",
    "\n",
    "            # Advance the episode by executing the selected action.\n",
    "            (obs, reward, term, trunc, info) = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if term or trunc:\n",
    "                break\n",
    "        return (observations, actions, torch.cat(log_probs), rewards)\n",
    "\n",
    "    # A direct, inefficient, and probably buggy of the REINFORCE policy gradient algorithm.\n",
    "    def reinforce(self):\n",
    "        # The only non-vanilla part: we use Adam instead of SGD.\n",
    "        opt = torch.optim.Adam(self.policy.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Track episode rewards in a list.\n",
    "        running_rewards = [0.0]\n",
    "\n",
    "        # The main training loop.\n",
    "        self.policy.train()\n",
    "        for episode in range(self.num_episodes):\n",
    "            # Run an episode of the environment, collect everything needed for policy update.\n",
    "            (observations, actions, log_probs, rewards) = self.run_episode()\n",
    "\n",
    "            # Compute the discounted reward for every step of the episode.\n",
    "            returns = torch.tensor(self.compute_returns(rewards), dtype=torch.float32)\n",
    "\n",
    "            # Keep a running average of total discounted rewards for the whole episode.\n",
    "            running_reward = 0.05 * returns[0].item() + 0.95 * running_rewards[-1]\n",
    "            running_rewards.append(running_reward)\n",
    "\n",
    "            # Standardize returns.\n",
    "            returns = (returns - returns.mean()) / returns.std()\n",
    "\n",
    "            # Make an optimization step\n",
    "            opt.zero_grad()\n",
    "            loss = (-log_probs * returns).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            metrics = {\"Policy Loss\": loss,\n",
    "                       \"Running Reward\": running_reward}\n",
    "            wandb.log({**metrics}) \n",
    "\n",
    "            # Render an episode after every 100 policy updates.\n",
    "            if not episode % self.N:\n",
    "                self.policy.eval()\n",
    "                (obs, _, _, _) = self.run_episode(display=True)\n",
    "                self.policy.train()\n",
    "                print(f'Running reward: {running_rewards[-1]}')\n",
    "\n",
    "        # Return the running rewards.\n",
    "        self.policy.eval()\n",
    "        return (running_rewards, self.policy.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3447d",
   "metadata": {},
   "source": [
    "Run with initial algorithm (2000 episodes, gamma = 0.99, temperature = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cd8472-e157-4463-bbc7-2ef88cded62c",
   "metadata": {
    "id": "92cd8472-e157-4463-bbc7-2ef88cded62c",
    "outputId": "5e7350ee-ec24-45cf-e515-e062c98a7f8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_164735-9u164nz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/9u164nz6' target=\"_blank\">Reinforce</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/9u164nz6' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/9u164nz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 0.6497082233428956\n",
      "Running reward: 23.190019938114148\n",
      "Running reward: 34.2965949373752\n",
      "Running reward: 82.70511604452692\n",
      "Running reward: 93.05599589222612\n",
      "Running reward: 97.93792739779911\n",
      "Running reward: 97.94823068770908\n",
      "Running reward: 97.4321737049628\n",
      "Running reward: 97.27579236350714\n",
      "Running reward: 98.13662530975331\n",
      "Running reward: 98.19534296458968\n",
      "Running reward: 98.33517156102218\n",
      "Running reward: 98.26824690796535\n",
      "Running reward: 95.66775462775256\n",
      "Running reward: 97.85358418639588\n",
      "Running reward: 93.03835264075786\n",
      "Running reward: 98.25870593512299\n",
      "Running reward: 98.34898775205852\n",
      "Running reward: 98.34952226819374\n",
      "Running reward: 96.9865712025036\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9u164nz6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>▄▃▂▃▄▂▃▂▆▄▅▃▂▄▅▃▄▅▅▁█▄▃▁▅▄▄▃▂▄▃▃▅▄▆▂▄▄▄▁</td></tr><tr><td>Running Reward</td><td>▁▂▂▂▃▅▇█████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>-0.00899</td></tr><tr><td>Running Reward</td><td>98.34103</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/9u164nz6' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/9u164nz6</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_164735-9u164nz6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9u164nz6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_170554-nsy4av0p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/nsy4av0p' target=\"_blank\">Reinforce</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/nsy4av0p' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/nsy4av0p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 0.42808961868286133\n",
      "Running reward: 25.863219355172127\n",
      "Running reward: 48.50486924684883\n",
      "Running reward: 82.82855868124207\n",
      "Running reward: 94.0840698403936\n",
      "Running reward: 96.56840462011412\n",
      "Running reward: 98.00008763034171\n",
      "Running reward: 77.04336354226602\n",
      "Running reward: 96.82797656644448\n",
      "Running reward: 97.15818445644356\n",
      "Running reward: 98.02453171861248\n",
      "Running reward: 98.34760131676703\n",
      "Running reward: 98.08222405243808\n",
      "Running reward: 98.31886604104206\n",
      "Running reward: 98.3493439317235\n",
      "Running reward: 98.34952437696586\n",
      "Running reward: 98.1931484449106\n",
      "Running reward: 98.34717201039915\n",
      "Running reward: 98.2168495838246\n",
      "Running reward: 96.20843634915487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nsy4av0p) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>▅▃▁▂▆▅▃▅▅▄▅▄▆▄▄▆▄▅▅▅▆▄▇▄▄█▅▄▄▄▅▄▅▅▄▄▅▄▇▇</td></tr><tr><td>Running Reward</td><td>▁▂▂▃▄▆▇██▇███▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>-0.01536</td></tr><tr><td>Running Reward</td><td>97.1594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/nsy4av0p' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/nsy4av0p</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_170554-nsy4av0p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nsy4av0p). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_172319-94yemplu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/94yemplu' target=\"_blank\">Reinforce</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/94yemplu' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/94yemplu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 1.0608932495117187\n",
      "Running reward: 21.76099091345924\n",
      "Running reward: 57.34512706294905\n",
      "Running reward: 91.65530371034195\n",
      "Running reward: 95.37254665452285\n",
      "Running reward: 90.49952093055856\n",
      "Running reward: 97.88843788111278\n",
      "Running reward: 98.32094715222074\n",
      "Running reward: 96.65827759649117\n",
      "Running reward: 98.12478714637611\n",
      "Running reward: 98.34819488195659\n",
      "Running reward: 97.59485343813407\n",
      "Running reward: 91.70991170071443\n",
      "Running reward: 82.90690033189746\n",
      "Running reward: 73.33164629858186\n",
      "Running reward: 78.9565067622796\n",
      "Running reward: 71.85287770872525\n",
      "Running reward: 86.06232391771704\n",
      "Running reward: 97.87107920308149\n",
      "Running reward: 97.88316670816815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:94yemplu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>▂▁▄▅▂▁▁▁▂▂▅▃▃▂▃▃▃▃▂▃▃▃▄▃▃▂▂▃▂▃▅▅█▂▄▃▃▃▂▃</td></tr><tr><td>Running Reward</td><td>▁▂▂▄▅▇███▇██████████████▇▇▇▆▆▇▆▆▆▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>-0.00332</td></tr><tr><td>Running Reward</td><td>97.88481</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/94yemplu' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/94yemplu</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_172319-94yemplu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:94yemplu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_173800-efqsu0tg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/efqsu0tg' target=\"_blank\">Reinforce</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/efqsu0tg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/efqsu0tg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 0.7774312019348145\n",
      "Running reward: 21.03520649842848\n",
      "Running reward: 46.62653593972456\n",
      "Running reward: 92.65362679618268\n",
      "Running reward: 96.47210269742361\n",
      "Running reward: 95.46401282522424\n",
      "Running reward: 98.15981128381767\n",
      "Running reward: 97.41286383968063\n",
      "Running reward: 98.32258456860892\n",
      "Running reward: 98.06122814343607\n",
      "Running reward: 98.17195798977701\n",
      "Running reward: 98.22462588853817\n",
      "Running reward: 98.19977529855937\n",
      "Running reward: 98.34863885150278\n",
      "Running reward: 98.34952020251781\n",
      "Running reward: 98.3264891936881\n",
      "Running reward: 98.25080875853736\n",
      "Running reward: 97.74985769077867\n",
      "Running reward: 98.34434074889974\n",
      "Running reward: 96.50468099790825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:efqsu0tg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>▃█▁▃▄▂▃▂▃▂▃▂▃▃▆▂▃▃▄▃▅▂▅▃▄▂▃▃▄▂▃▂▃▃▃▂▃▁▄▂</td></tr><tr><td>Running Reward</td><td>▁▂▂▃▄▆██████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>0.00449</td></tr><tr><td>Running Reward</td><td>98.30753</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/efqsu0tg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/efqsu0tg</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_173800-efqsu0tg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:efqsu0tg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_175645-zwsmw9wl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/zwsmw9wl' target=\"_blank\">Reinforce</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/zwsmw9wl' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/zwsmw9wl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: 0.7774312019348145\n",
      "Running reward: 28.666278900224185\n",
      "Running reward: 68.36353509333874\n",
      "Running reward: 95.22789090103967\n",
      "Running reward: 95.40643687839002\n",
      "Running reward: 97.07285936001247\n",
      "Running reward: 96.68920068707166\n",
      "Running reward: 98.30876741683528\n",
      "Running reward: 98.31645413151655\n",
      "Running reward: 98.00210736414499\n",
      "Running reward: 98.34746855272117\n",
      "Running reward: 97.74791352321091\n",
      "Running reward: 98.07643203330349\n",
      "Running reward: 98.31865023424464\n",
      "Running reward: 98.3493426540331\n",
      "Running reward: 98.25732959429939\n",
      "Running reward: 96.06293294061365\n",
      "Running reward: 98.0593281013731\n",
      "Running reward: 98.10253615536354\n",
      "Running reward: 96.66928990583492\n"
     ]
    }
   ],
   "source": [
    "# Your code here. You should be able to train an agent to solve Cartpole. This will be our starting point.\n",
    "\n",
    "n_run = 5\n",
    "seeds = [11, 111, 1111, 11111, 111111]\n",
    "val_seeds = [22, 222, 22222, 22222, 222222]\n",
    "\n",
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    #Instantiate a rendering and a non rendering environment\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    #track run\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"Reinforce\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"architecture\": \"REINFORCE\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 20})\n",
    "\n",
    "    # Make a policy network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "\n",
    "    # Train the agent.\n",
    "    r = Reinforce(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"], N=run.config[\"N\"])\n",
    "    (rewards, state_dict) = r.reinforce()\n",
    "    \n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9ba929-4270-4ff8-9a04-75f064b3fa23",
   "metadata": {
    "id": "7d9ba929-4270-4ff8-9a04-75f064b3fa23",
    "outputId": "d546dd32-2673-46d7-dd47-26bf037e7dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 500.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>▆▄▁▅▃▃▆▇▅▆▇▆▄▅▅▇▆▆▇▇▆▇▆▅▆▅▄▃▄▇▅▅▇▇█▆█▆▆▄</td></tr><tr><td>Running Reward</td><td>▁▂▃▄▆███████████████████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Policy Loss</td><td>-0.00856</td></tr><tr><td>Running Reward</td><td>98.33905</td></tr><tr><td>Total average test reward</td><td>500.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/zwsmw9wl' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/zwsmw9wl</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_175645-zwsmw9wl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b8a90f-78ed-4f43-9d66-aeba7c74fe2c",
   "metadata": {
    "id": "18b8a90f-78ed-4f43-9d66-aeba7c74fe2c"
   },
   "source": [
    "**Last Things Last**: My implementation does a **super crappy** job of evaluating the agent performance during training. The running average is not a very good metric. Modify my implementation so that every $N$ iterations (make $N$ an argument to the training function) the agent is run for $M$ episodes in the environment. Collect and return: (1) The average **total** reward received over the $M$ iterations; and (2) the average episode length. Analyze the performance of your agents with these new metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f787adb5-e925-4e10-b3f7-b4dc2f7fe6d9",
   "metadata": {
    "id": "f787adb5-e925-4e10-b3f7-b4dc2f7fe6d9"
   },
   "outputs": [],
   "source": [
    "class ReinforceAvg(Reinforce):\n",
    "    def __init__(self, policy, env, env_render=None, gamma=0.99, num_episodes=10, lr=1e-2,\n",
    "                 max_len=500, N=100, eval_episodes=10):\n",
    "        super().__init__(policy, env, env_render, gamma, num_episodes, lr, max_len, N)\n",
    "        self.M = eval_episodes\n",
    "\n",
    "    def run_episode(self, display=False, test=False):\n",
    "        # Collect just about everything.\n",
    "        observations = []\n",
    "        actions = []\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        env = self.environment\n",
    "        if display:\n",
    "            env = self.env_render\n",
    "\n",
    "        # Reset the environment and start the episode.\n",
    "        (obs, info) = env.reset()\n",
    "        for i in range(self.max_len):\n",
    "            # Get the current observation, run the policy and select an action.\n",
    "            obs = torch.tensor(obs)\n",
    "            if test:\n",
    "                (action,log_prob) = self.select_max_action(obs)\n",
    "            else:\n",
    "                (action, log_prob) = self.select_action(obs)\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            log_probs.append(log_prob)\n",
    "\n",
    "            # Advance the episode by executing the selected action.\n",
    "            (obs, reward, term, trunc, info) = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if term or trunc:\n",
    "                break\n",
    "        length = i + 1\n",
    "        return (observations, actions, torch.cat(log_probs), rewards, length)\n",
    "\n",
    "    def reinforce(self):\n",
    "        # The only non-vanilla part: we use Adam instead of SGD.\n",
    "        opt = torch.optim.Adam(self.policy.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Track episode rewards in a list.\n",
    "        running_rewards = [0.0]\n",
    "        average_rewards = []\n",
    "        average_lengths = []\n",
    "\n",
    "        # The main training loop.\n",
    "        self.policy.train()\n",
    "        state_dict = None\n",
    "        best_reward = 0\n",
    "        for episode in range(self.num_episodes):\n",
    "            # Run an episode of the environment, collect everything needed for policy update.\n",
    "            (observations, actions, log_probs, rewards, length) = self.run_episode()\n",
    "\n",
    "            # Compute the discounted reward for every step of the episode.\n",
    "            returns = torch.tensor(self.compute_returns(rewards), dtype=torch.float32)\n",
    "\n",
    "            # Keep a running average of total discounted rewards for the whole episode.\n",
    "            running_reward = 0.05 * returns[0].item() + 0.95 * running_rewards[-1]\n",
    "            running_rewards.append(running_reward)\n",
    "\n",
    "            # Standardize returns.\n",
    "            returns = (returns - returns.mean()) / returns.std()\n",
    "\n",
    "            # Make an optimization step\n",
    "            opt.zero_grad()\n",
    "            loss = (-log_probs * returns).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            metrics = {\"Policy Loss\": loss,\n",
    "                       \"Running Reward\": running_reward}\n",
    "            wandb.log({**metrics})\n",
    "\n",
    "            # Render an episode after every 100 policy updates.\n",
    "            if not episode % self.N:\n",
    "                self.policy.eval()\n",
    "                total_reward = 0\n",
    "                total_length = 0\n",
    "                for _ in range(self.M):\n",
    "                    (_, _, _, rewards, length) = self.run_episode()\n",
    "                    total_reward += np.sum(rewards)\n",
    "                    total_length += length\n",
    "                average_reward = total_reward / self.M\n",
    "                average_rewards.append(average_reward)\n",
    "                print(f'Average Total: {average_reward}')\n",
    "                average_length = total_length / self.M\n",
    "                average_lengths.append(average_length)\n",
    "                print(f'Average Length: {average_length}')\n",
    "\n",
    "                val_metrics = {\"Average Total Reward\": average_reward,\n",
    "                               \"Average Length\": average_length}\n",
    "                wandb.log({**val_metrics})\n",
    "\n",
    "                if average_reward >= best_reward:\n",
    "                    best_reward = average_reward\n",
    "                    state_dict = self.policy.state_dict()\n",
    "\n",
    "                (obs, _, _, _, _) = self.run_episode(display=True)\n",
    "                self.policy.train()\n",
    "                print(f'Running reward: {running_rewards[-1]}')\n",
    "\n",
    "        # Return the running rewards.\n",
    "        self.policy.eval()\n",
    "        return (running_rewards, average_rewards, average_lengths, state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b714361",
   "metadata": {},
   "source": [
    "Runs varying hyperparameters, with validation and average total reward and length for episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f5ca44-81a8-4b06-b844-71124f49ef9a",
   "metadata": {
    "id": "31f5ca44-81a8-4b06-b844-71124f49ef9a",
    "outputId": "d55557d0-a0a7-4697-e67d-56d8ac5a2153",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_183301-3c79m2qf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3c79m2qf' target=\"_blank\">ReinforceAvg lower gamma</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3c79m2qf' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/3c79m2qf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 26.1\n",
      "Average Length: 26.1\n",
      "Running reward: 0.3960641145706177\n",
      "Average Total: 29.6\n",
      "Average Length: 29.6\n",
      "Running reward: 9.704630357956068\n",
      "Average Total: 64.1\n",
      "Average Length: 64.1\n",
      "Running reward: 10.767900320285971\n",
      "Average Total: 128.3\n",
      "Average Length: 128.3\n",
      "Running reward: 11.436967272403658\n",
      "Average Total: 353.0\n",
      "Average Length: 353.0\n",
      "Running reward: 11.492468479901543\n",
      "Average Total: 172.9\n",
      "Average Length: 172.9\n",
      "Running reward: 11.424512905761132\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.495140430880197\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499887142211803\n",
      "Average Total: 413.6\n",
      "Average Length: 413.6\n",
      "Running reward: 11.496445273747195\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49540190266793\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499972776830365\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999838824404\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999045732\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999994325\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49999999999994\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.484353678822917\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499907365498256\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999451554698\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49999999675289\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999980751\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3c79m2qf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▂▃▆▃██▇███████████</td></tr><tr><td>Average Total Reward</td><td>▁▁▂▃▆▃██▇███████████</td></tr><tr><td>Policy Loss</td><td>▆▆▅▁▃▃▇▄▅▄▅▆▆▆▆▆▅▄█▅▅▆▄▆▅▅▆▆▄▆▅▅▅▅▄▅▆▅▆▇</td></tr><tr><td>Running Reward</td><td>▁▆▆▆▇███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>-0.01677</td></tr><tr><td>Running Reward</td><td>11.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower gamma</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3c79m2qf' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/3c79m2qf</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_183301-3c79m2qf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3c79m2qf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_185110-xppmafr3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/xppmafr3' target=\"_blank\">ReinforceAvg lower gamma</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/xppmafr3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/xppmafr3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 22.0\n",
      "Average Length: 22.0\n",
      "Running reward: 0.3035072088241577\n",
      "Average Total: 29.9\n",
      "Average Length: 29.9\n",
      "Running reward: 9.314940477113208\n",
      "Average Total: 74.8\n",
      "Average Length: 74.8\n",
      "Running reward: 11.156722728170807\n",
      "Average Total: 108.9\n",
      "Average Length: 108.9\n",
      "Running reward: 11.430517254837257\n",
      "Average Total: 157.2\n",
      "Average Length: 157.2\n",
      "Running reward: 11.492831622802584\n",
      "Average Total: 281.7\n",
      "Average Length: 281.7\n",
      "Running reward: 11.499814069222595\n",
      "Average Total: 194.8\n",
      "Average Length: 194.8\n",
      "Running reward: 11.484491454387348\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499129462451933\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499994845956985\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999969485314\n",
      "Average Total: 477.0\n",
      "Average Length: 477.0\n",
      "Running reward: 11.499999999819313\n",
      "Average Total: 497.1\n",
      "Average Length: 497.1\n",
      "Running reward: 11.499999999998908\n",
      "Average Total: 480.5\n",
      "Average Length: 480.5\n",
      "Running reward: 11.493494939859666\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49444125944099\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499963123981884\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999781674433\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999998707372\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999992324\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49999999999993\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49999999999996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xppmafr3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▂▂▃▅▄█████████████</td></tr><tr><td>Average Total Reward</td><td>▁▁▂▂▃▅▄█████████████</td></tr><tr><td>Policy Loss</td><td>▅▃▅▄▁▇▄▅▇▅▂▇▃▄▆█▅▄▅▇▅▄▄▄▄▄▆▄▇▅▄▅▆▃▄▅▃▅▄▅</td></tr><tr><td>Running Reward</td><td>▁▅▆▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>-0.01291</td></tr><tr><td>Running Reward</td><td>11.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower gamma</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/xppmafr3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/xppmafr3</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_185110-xppmafr3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xppmafr3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_190848-z59m0k4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/z59m0k4y' target=\"_blank\">ReinforceAvg lower gamma</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/z59m0k4y' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/z59m0k4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 23.9\n",
      "Average Length: 23.9\n",
      "Running reward: 0.4972723007202149\n",
      "Average Total: 25.5\n",
      "Average Length: 25.5\n",
      "Running reward: 9.464758245217674\n",
      "Average Total: 60.5\n",
      "Average Length: 60.5\n",
      "Running reward: 10.900748623670577\n",
      "Average Total: 130.1\n",
      "Average Length: 130.1\n",
      "Running reward: 11.384159032809848\n",
      "Average Total: 313.1\n",
      "Average Length: 313.1\n",
      "Running reward: 11.494048335591792\n",
      "Average Total: 111.9\n",
      "Average Length: 111.9\n",
      "Running reward: 11.471558266447634\n",
      "Average Total: 328.9\n",
      "Average Length: 328.9\n",
      "Running reward: 11.433333214352109\n",
      "Average Total: 461.1\n",
      "Average Length: 461.1\n",
      "Running reward: 11.494848494083826\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49996933630357\n",
      "Average Total: 318.0\n",
      "Average Length: 318.0\n",
      "Running reward: 11.499999682556076\n",
      "Average Total: 490.0\n",
      "Average Length: 490.0\n",
      "Running reward: 11.499999969724346\n",
      "Average Total: 432.0\n",
      "Average Length: 432.0\n",
      "Running reward: 11.499951406161763\n",
      "Average Total: 455.9\n",
      "Average Length: 455.9\n",
      "Running reward: 11.499992574500641\n",
      "Average Total: 143.2\n",
      "Average Length: 143.2\n",
      "Running reward: 11.499954624891313\n",
      "Average Total: 491.7\n",
      "Average Length: 491.7\n",
      "Running reward: 11.492723393235348\n",
      "Average Total: 455.5\n",
      "Average Length: 455.5\n",
      "Running reward: 11.499479055265157\n",
      "Average Total: 460.4\n",
      "Average Length: 460.4\n",
      "Running reward: 11.499996915731453\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.492841451586115\n",
      "Average Total: 384.5\n",
      "Average Length: 384.5\n",
      "Running reward: 11.499957617604919\n",
      "Average Total: 466.1\n",
      "Average Length: 466.1\n",
      "Running reward: 11.499999749073769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z59m0k4y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▂▃▅▂▅▇█▅█▇▇▃█▇▇█▆█</td></tr><tr><td>Average Total Reward</td><td>▁▁▂▃▅▂▅▇█▅█▇▇▃█▇▇█▆█</td></tr><tr><td>Policy Loss</td><td>▇▇▆▇▁▇▇█▆▇▆▆▇▇▇▇▇▆▇▇█▇▇▇▇▇▆▇▇██▇▇▇▇▇▆▇▇▇</td></tr><tr><td>Running Reward</td><td>▁▅▆▆▇███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>466.1</td></tr><tr><td>Average Total Reward</td><td>466.1</td></tr><tr><td>Policy Loss</td><td>0.00253</td></tr><tr><td>Running Reward</td><td>11.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower gamma</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/z59m0k4y' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/z59m0k4y</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_190848-z59m0k4y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z59m0k4y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_192428-cusvx1x7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/cusvx1x7' target=\"_blank\">ReinforceAvg lower gamma</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/cusvx1x7' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/cusvx1x7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 21.2\n",
      "Average Length: 21.2\n",
      "Running reward: 0.43566479682922366\n",
      "Average Total: 49.9\n",
      "Average Length: 49.9\n",
      "Running reward: 9.872335727198276\n",
      "Average Total: 77.9\n",
      "Average Length: 77.9\n",
      "Running reward: 11.332912167667539\n",
      "Average Total: 260.9\n",
      "Average Length: 260.9\n",
      "Running reward: 11.43249004610792\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.483380017838329\n",
      "Average Total: 412.8\n",
      "Average Length: 412.8\n",
      "Running reward: 11.499685875702824\n",
      "Average Total: 339.2\n",
      "Average Length: 339.2\n",
      "Running reward: 11.49960380057938\n",
      "Average Total: 410.3\n",
      "Average Length: 410.3\n",
      "Running reward: 11.474441784154077\n",
      "Average Total: 481.2\n",
      "Average Length: 481.2\n",
      "Running reward: 11.499836115357384\n",
      "Average Total: 483.5\n",
      "Average Length: 483.5\n",
      "Running reward: 11.499982966908515\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.498210679960195\n",
      "Average Total: 476.5\n",
      "Average Length: 476.5\n",
      "Running reward: 11.452192032789084\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499716951533141\n",
      "Average Total: 444.6\n",
      "Average Length: 444.6\n",
      "Running reward: 11.499908154728166\n",
      "Average Total: 403.8\n",
      "Average Length: 403.8\n",
      "Running reward: 11.49999945622736\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999995862039\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999975476\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49998859369142\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.48701733222874\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.492991437940747\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cusvx1x7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▂▅█▇▆▇█████▇▇█████</td></tr><tr><td>Average Total Reward</td><td>▁▁▂▅█▇▆▇█████▇▇█████</td></tr><tr><td>Policy Loss</td><td>▄█▁▃▅▂▅▄▄▄▄▅▄▄▅▅▅▃▅▆▄▄▄▄▅▆▅▄▆▅▄▃▄▄▄▅▃▄▄▄</td></tr><tr><td>Running Reward</td><td>▁▅▆▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>-0.0105</td></tr><tr><td>Running Reward</td><td>11.49996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower gamma</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/cusvx1x7' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/cusvx1x7</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_192428-cusvx1x7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cusvx1x7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_194308-x4x2aib3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/x4x2aib3' target=\"_blank\">ReinforceAvg lower gamma</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/x4x2aib3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/x4x2aib3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 31.9\n",
      "Average Length: 31.9\n",
      "Running reward: 0.43566479682922366\n",
      "Average Total: 24.8\n",
      "Average Length: 24.8\n",
      "Running reward: 9.166403752386982\n",
      "Average Total: 44.4\n",
      "Average Length: 44.4\n",
      "Running reward: 11.008327461913176\n",
      "Average Total: 116.6\n",
      "Average Length: 116.6\n",
      "Running reward: 11.39817018599383\n",
      "Average Total: 297.1\n",
      "Average Length: 297.1\n",
      "Running reward: 11.49307012171752\n",
      "Average Total: 395.6\n",
      "Average Length: 395.6\n",
      "Running reward: 11.498879004876944\n",
      "Average Total: 135.7\n",
      "Average Length: 135.7\n",
      "Running reward: 11.270078701480966\n",
      "Average Total: 386.0\n",
      "Average Length: 386.0\n",
      "Running reward: 11.49308857102441\n",
      "Average Total: 283.2\n",
      "Average Length: 283.2\n",
      "Running reward: 11.446263014114743\n",
      "Average Total: 469.0\n",
      "Average Length: 469.0\n",
      "Running reward: 11.499681848604828\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49984391328684\n",
      "Average Total: 462.4\n",
      "Average Length: 462.4\n",
      "Running reward: 11.49999907588403\n",
      "Average Total: 487.8\n",
      "Average Length: 487.8\n",
      "Running reward: 11.499999150179674\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.444302599707726\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499579256251018\n",
      "Average Total: 387.7\n",
      "Average Length: 387.7\n",
      "Running reward: 11.499996801765388\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.49999998106473\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999887871\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 11.499999999999314\n",
      "Average Total: 325.8\n",
      "Average Length: 325.8\n",
      "Running reward: 11.476164678446814\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    #Instantiate a rendering and a non rendering environment\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"ReinforceAvg lower gamma\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"architecture\": \"REINFORCE_AVG\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.92,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 20,\n",
    "          \"M\": 10})\n",
    "    \n",
    "    # Make a policy network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "\n",
    "    # Train the agent.\n",
    "    r = ReinforceAvg(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()\n",
    "\n",
    "#provare anche a diminuire hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd7e2ea-a1c3-40fb-838e-418b9ebd0d2f",
   "metadata": {
    "id": "2cd7e2ea-a1c3-40fb-838e-418b9ebd0d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 500.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▁▂▅▆▃▆▅██▇███▆███▅</td></tr><tr><td>Average Total Reward</td><td>▁▁▁▂▅▆▃▆▅██▇███▆███▅</td></tr><tr><td>Policy Loss</td><td>▄▅▄▅█▅▆▄▄▅▄▄▁▄▄▅▄▄▄▅▅▄▄▄▄▄▄▄▅▄▄▄▄▅▄▅▄▄▄▅</td></tr><tr><td>Running Reward</td><td>▁▅▆▇▇███████████████████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>325.8</td></tr><tr><td>Average Total Reward</td><td>325.8</td></tr><tr><td>Policy Loss</td><td>-0.0021</td></tr><tr><td>Running Reward</td><td>11.49985</td></tr><tr><td>Total average test reward</td><td>500.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower gamma</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/x4x2aib3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/x4x2aib3</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_194308-x4x2aib3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df2c2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_201647-6884ynq6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6884ynq6' target=\"_blank\">ReinforceAvg lower T</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6884ynq6' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/6884ynq6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 26.1\n",
      "Average Length: 26.1\n",
      "Running reward: 0.6497082233428956\n",
      "Average Total: 59.4\n",
      "Average Length: 59.4\n",
      "Running reward: 39.347795523237224\n",
      "Average Total: 424.0\n",
      "Average Length: 424.0\n",
      "Running reward: 87.32869074964754\n",
      "Average Total: 461.2\n",
      "Average Length: 461.2\n",
      "Running reward: 97.4552843648731\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.7742111894198\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.20799809789683\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.2133700963476\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.1758297435418\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.22037771741685\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.52594265140341\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.32728488819339\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.19207783210567\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.04145270893343\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.17720149173337\n",
      "Average Total: 463.5\n",
      "Average Length: 463.5\n",
      "Running reward: 96.87523796770098\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.89050575917663\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.48085916216404\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34247059588408\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3494836831802\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3093558187796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6884ynq6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▇▇██████████▇█████</td></tr><tr><td>Average Total Reward</td><td>▁▁▇▇██████████▇█████</td></tr><tr><td>Policy Loss</td><td>▆▇▆▆▅▅▆▆▄▅▄█▁▅▇▅▅▇▆█▃▆▅▇▂▅▄▃▄▅▆▆▇▃▄▅▇█▆▅</td></tr><tr><td>Running Reward</td><td>▁▂▄▆▇███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>0.00079</td></tr><tr><td>Running Reward</td><td>98.34928</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower T</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6884ynq6' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/6884ynq6</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_201647-6884ynq6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6884ynq6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_203723-c0nim39s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c0nim39s' target=\"_blank\">ReinforceAvg lower T</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c0nim39s' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c0nim39s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 22.2\n",
      "Average Length: 22.2\n",
      "Running reward: 0.42808961868286133\n",
      "Average Total: 18.6\n",
      "Average Length: 18.6\n",
      "Running reward: 16.36440253796899\n",
      "Average Total: 31.2\n",
      "Average Length: 31.2\n",
      "Running reward: 26.66849904100528\n",
      "Average Total: 87.1\n",
      "Average Length: 87.1\n",
      "Running reward: 53.85440465697726\n",
      "Average Total: 328.4\n",
      "Average Length: 328.4\n",
      "Running reward: 89.97042449802098\n",
      "Average Total: 223.9\n",
      "Average Length: 223.9\n",
      "Running reward: 88.02701860712041\n",
      "Average Total: 445.7\n",
      "Average Length: 445.7\n",
      "Running reward: 97.33720978096878\n",
      "Average Total: 187.5\n",
      "Average Length: 187.5\n",
      "Running reward: 86.99964191210253\n",
      "Average Total: 76.2\n",
      "Average Length: 76.2\n",
      "Running reward: 66.83412140993117\n",
      "Average Total: 188.2\n",
      "Average Length: 188.2\n",
      "Running reward: 82.48210826221373\n",
      "Average Total: 283.7\n",
      "Average Length: 283.7\n",
      "Running reward: 94.00736088958236\n",
      "Average Total: 205.0\n",
      "Average Length: 205.0\n",
      "Running reward: 94.50863231312991\n",
      "Average Total: 280.2\n",
      "Average Length: 280.2\n",
      "Running reward: 87.31770852837317\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.15618186289521\n",
      "Average Total: 483.8\n",
      "Average Length: 483.8\n",
      "Running reward: 94.15321026520589\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.67543299246948\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.51903142576653\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.17582200192737\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34849703531015\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34951936289089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:c0nim39s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▁▂▆▄▇▃▂▃▅▄▅███████</td></tr><tr><td>Average Total Reward</td><td>▁▁▁▂▆▄▇▃▂▃▅▄▅███████</td></tr><tr><td>Policy Loss</td><td>▆▃▁█▄▆▄▂▅▃▅▅▄▃▆▄▄▃▄▅▆▃▃▅▄▅▆▅▄▃▅▄▅▅▅▄▅▆▆▃</td></tr><tr><td>Running Reward</td><td>▁▂▂▂▂▄▅▇█▇▇██▇▇▆▅▆▆▇██▇▇████▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>-0.02959</td></tr><tr><td>Running Reward</td><td>97.61093</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower T</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c0nim39s' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c0nim39s</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_203723-c0nim39s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:c0nim39s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_205155-jjex5dcj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/jjex5dcj' target=\"_blank\">ReinforceAvg lower T</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/jjex5dcj' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/jjex5dcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 25.3\n",
      "Average Length: 25.3\n",
      "Running reward: 1.0608932495117187\n",
      "Average Total: 104.3\n",
      "Average Length: 104.3\n",
      "Running reward: 47.828443612874274\n",
      "Average Total: 455.7\n",
      "Average Length: 455.7\n",
      "Running reward: 91.52262721604303\n",
      "Average Total: 434.0\n",
      "Average Length: 434.0\n",
      "Running reward: 94.4630668193838\n",
      "Average Total: 143.3\n",
      "Average Length: 143.3\n",
      "Running reward: 80.96704893988772\n",
      "Average Total: 189.7\n",
      "Average Length: 189.7\n",
      "Running reward: 75.95496642354303\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.12179780283537\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34817718346082\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34951746919869\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33790851137228\n",
      "Average Total: 219.7\n",
      "Average Length: 219.7\n",
      "Running reward: 72.32367070855146\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.18155952251425\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34853100446843\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3495195640063\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.23951900758908\n",
      "Average Total: 244.7\n",
      "Average Length: 244.7\n",
      "Running reward: 93.50842748246005\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.79278087991418\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.06699644250823\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34785273040569\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34951554826488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jjex5dcj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▇▇▃▃████▄████▄████</td></tr><tr><td>Average Total Reward</td><td>▁▂▇▇▃▃████▄████▄████</td></tr><tr><td>Policy Loss</td><td>▂▃█▅▃▃▅▆▃▃▅▆▃▁▄▅▇▆▂▄▁▄▅▄▃▃▄▄▂▂▄▃▃▆▁▃▂▁▂▃</td></tr><tr><td>Running Reward</td><td>▁▃▄▆████▆▆▇████████▆▇█████████▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>0.01534</td></tr><tr><td>Running Reward</td><td>98.34953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower T</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/jjex5dcj' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/jjex5dcj</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_205155-jjex5dcj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jjex5dcj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_211059-e25rr38v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/e25rr38v' target=\"_blank\">ReinforceAvg lower T</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/e25rr38v' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/e25rr38v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 17.6\n",
      "Average Length: 17.6\n",
      "Running reward: 0.7774312019348145\n",
      "Average Total: 63.4\n",
      "Average Length: 63.4\n",
      "Running reward: 30.911007662428396\n",
      "Average Total: 280.6\n",
      "Average Length: 280.6\n",
      "Running reward: 82.61082721961085\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.22373255041809\n",
      "Average Total: 435.9\n",
      "Average Length: 435.9\n",
      "Running reward: 97.48509009859872\n",
      "Average Total: 450.1\n",
      "Average Length: 450.1\n",
      "Running reward: 97.15320673544689\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.5736432886379\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33309076020156\n",
      "Average Total: 484.9\n",
      "Average Length: 484.9\n",
      "Running reward: 98.34942814958896\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33157593908335\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.23227878866895\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 94.51695138562508\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.59801497903715\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 93.37415149278442\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32006860475433\n",
      "Average Total: 463.3\n",
      "Average Length: 463.3\n",
      "Running reward: 97.14429044664055\n",
      "Average Total: 108.3\n",
      "Average Length: 108.3\n",
      "Running reward: 55.88093523813705\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.31089292381007\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34337619742963\n",
      "Average Total: 234.3\n",
      "Average Length: 234.3\n",
      "Running reward: 95.7871255345088\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e25rr38v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▅█▇▇█████████▇▂██▄</td></tr><tr><td>Average Total Reward</td><td>▁▂▅█▇▇█████████▇▂██▄</td></tr><tr><td>Policy Loss</td><td>▇▂▁▅▆█▇▇▆▇▆▆▆▆▅▅▅▇▆▆▅▄▆▆▅▆▄█▆▅█▅▆▅▆▇▆▇▆▇</td></tr><tr><td>Running Reward</td><td>▁▂▃▅▇████▇█▇██████████████████▆▅▆█████▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>234.3</td></tr><tr><td>Average Total Reward</td><td>234.3</td></tr><tr><td>Policy Loss</td><td>0.00441</td></tr><tr><td>Running Reward</td><td>94.96179</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower T</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/e25rr38v' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/e25rr38v</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_211059-e25rr38v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e25rr38v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_212933-arpulzgx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/arpulzgx' target=\"_blank\">ReinforceAvg lower T</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/arpulzgx' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/arpulzgx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Total: 31.9\n",
      "Average Length: 31.9\n",
      "Running reward: 0.7774312019348145\n",
      "Average Total: 28.4\n",
      "Average Length: 28.4\n",
      "Running reward: 24.377308287412447\n",
      "Average Total: 188.0\n",
      "Average Length: 188.0\n",
      "Running reward: 78.70860525450098\n",
      "Average Total: 404.9\n",
      "Average Length: 404.9\n",
      "Running reward: 95.86506714537013\n",
      "Average Total: 435.8\n",
      "Average Length: 435.8\n",
      "Running reward: 95.14123001529926\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.30091003541413\n",
      "Average Total: 466.5\n",
      "Average Length: 466.5\n",
      "Running reward: 97.98720888660506\n",
      "Average Total: 291.0\n",
      "Average Length: 291.0\n",
      "Running reward: 88.35950526231758\n",
      "Average Total: 168.9\n",
      "Average Length: 168.9\n",
      "Running reward: 68.2593934495506\n",
      "Average Total: 403.0\n",
      "Average Length: 403.0\n",
      "Running reward: 97.63266507433812\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.00130962151316\n",
      "Average Total: 402.7\n",
      "Average Length: 402.7\n",
      "Running reward: 97.11364544533767\n",
      "Average Total: 318.6\n",
      "Average Length: 318.6\n",
      "Running reward: 95.96090992142119\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.57664894616651\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.25122684828119\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34894347190634\n",
      "Average Total: 497.7\n",
      "Average Length: 497.7\n",
      "Running reward: 98.3495220060318\n",
      "Average Total: 476.8\n",
      "Average Length: 476.8\n",
      "Running reward: 98.17799269294994\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3483930695133\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.66375950849378\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    #Instantiate a rendering and a non rendering environment\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"ReinforceAvg lower T\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"architecture\": \"REINFORCE_AVG\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 10,\n",
    "          \"M\": 10})\n",
    "    \n",
    "    # Make a policy network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"] , T=run.config[\"temperature\"])\n",
    "\n",
    "    # Train the agent.\n",
    "    r = ReinforceAvg(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d6475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 500.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▃▇▇██▅▃▇█▇▅███████</td></tr><tr><td>Average Total Reward</td><td>▁▁▃▇▇██▅▃▇█▇▅███████</td></tr><tr><td>Policy Loss</td><td>▆▅▅▇▆▆▇▆▆▄▇█▆▇▅▁▆▆▃▇▇▅▇▆▄▅▆▅▇▅▆▄▅▅▅▅▆▆▇▄</td></tr><tr><td>Running Reward</td><td>▁▂▃▅▇██▇██████▇▇▇██▇████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Policy Loss</td><td>0.00965</td></tr><tr><td>Running Reward</td><td>98.29517</td></tr><tr><td>Total average test reward</td><td>500.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceAvg lower T</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/arpulzgx' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/arpulzgx</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_212933-arpulzgx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5adad7-759b-4000-925b-701f41fe6e97",
   "metadata": {
    "id": "2a5adad7-759b-4000-925b-701f41fe6e97"
   },
   "source": [
    "-----\n",
    "## Exercise 2: `REINFORCE` with a Value Baseline (warm up)\n",
    "\n",
    "In this exercise we will augment my implementation (or your own) of `REINFORCE` to subtract a baseline from the target in the update equation in order to stabilize (and hopefully speed-up) convergence. For now we will stick to the Cartpole environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b8cf76-5d39-45e9-8d7d-324125c04b4a",
   "metadata": {
    "id": "d8b8cf76-5d39-45e9-8d7d-324125c04b4a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, env, inner_size=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(env.observation_space.shape[0], inner_size)\n",
    "        self.fc2 = nn.Linear(inner_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = F.relu(self.fc1(s))\n",
    "        s = self.fc2(s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd5bc3-a439-4d84-891b-f4a840331e07",
   "metadata": {
    "id": "8cdd5bc3-a439-4d84-891b-f4a840331e07"
   },
   "source": [
    "**First Things First**: Recall from the slides on Deep Reinforcement Learning that we can **subtract** any function that doesn't depend on the current action from the q-value without changing the (maximum of our) objecttive function $J$:  \n",
    "\n",
    "$$ \\nabla J(\\boldsymbol{\\theta}) \\propto \\sum_{s} \\mu(s) \\sum_a \\left( q_{\\pi}(s, a) - b(s) \\right) \\nabla \\pi(a \\mid s, \\boldsymbol{\\theta}) $$\n",
    "\n",
    "In `REINFORCE` this means we can subtract from our target $G_t$:\n",
    "\n",
    "$$ \\boldsymbol{\\theta}_{t+1} \\triangleq \\boldsymbol{\\theta}_t + \\alpha (G_t - b(S_t)) \\frac{\\nabla \\pi(A_t \\mid s, \\boldsymbol{\\theta})}{\\pi(A_t \\mid s, \\boldsymbol{\\theta})} $$\n",
    "\n",
    "Since we are only interested in the **maximum** of our objective, we can also **rescale** our target by any function that also doesn't depend on the action. A **simple baseline** which is even independent of the state -- that is, it is **constant** for each episode -- is to just **standardize rewards within the episode**. So, we **subtract** the average return and **divide** by the variance of returns:\n",
    "\n",
    "$$ \\boldsymbol{\\theta}_{t+1} \\triangleq \\boldsymbol{\\theta}_t + \\alpha \\left(\\frac{G_t - \\bar{G}}{\\sigma_G}\\right) \\nabla  \\pi(A_t \\mid s, \\boldsymbol{\\theta}) $$\n",
    "\n",
    "This baseline is **already** implemented in my implementation of `REINFORCE`. Experiment with and without this standardization baseline and compare the performance. We are going to do something more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf5b245-9369-4ed9-b5f4-3a52bb975d3f",
   "metadata": {
    "id": "faf5b245-9369-4ed9-b5f4-3a52bb975d3f"
   },
   "outputs": [],
   "source": [
    "# Your code here. Modify your implementation of `REINFORCE` to optionally use the standardize baseline.\n",
    "\n",
    "class ReinforceStd(ReinforceAvg):\n",
    "    def __init__(self, policy, env, env_render=None, gamma=0.99, num_episodes=10, lr=1e-2,\n",
    "                 max_len=500, N=100, eval_episodes=10, baseline=None):\n",
    "        super().__init__(policy, env, env_render, gamma, num_episodes, lr, max_len, N, eval_episodes)\n",
    "        self.baseline = baseline\n",
    "\n",
    "    # A direct, inefficient, and probably buggy of the REINFORCE policy gradient algorithm.\n",
    "    def reinforce(self):\n",
    "        # The only non-vanilla part: we use Adam instead of SGD.\n",
    "        opt = torch.optim.Adam(self.policy.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # If we have a baseline network, create the optimizer.\n",
    "        if self.baseline == 'std':\n",
    "            print('Training agent with standardization baseline.')\n",
    "        else:\n",
    "            print('Training agent with no baseline.')\n",
    "\n",
    "        # Track episode rewards in a list.\n",
    "        running_rewards = [0.0]\n",
    "        average_rewards = []\n",
    "        average_lengths = []\n",
    "\n",
    "        # The main training loop.\n",
    "        self.policy.train()\n",
    "        state_dict = None\n",
    "        best_reward = 0\n",
    "        for episode in range(self.num_episodes):\n",
    "            # Run an episode of the environment, collect everything needed for policy update.\n",
    "            (observations, actions, log_probs, rewards, length) = self.run_episode()\n",
    "\n",
    "            # Compute the discounted reward for every step of the episode.\n",
    "            returns = torch.tensor(self.compute_returns(rewards), dtype=torch.float32)\n",
    "\n",
    "            # Keep a running average of total discounted rewards for the whole episode.\n",
    "            running_reward = 0.05 * returns[0].item() + 0.95 * running_rewards[-1]\n",
    "            running_rewards.append(running_reward)\n",
    "\n",
    "            # Handle baseline.\n",
    "            if self.baseline == 'std':\n",
    "                target = (returns - returns.mean()) / returns.std()\n",
    "            else:\n",
    "                target = returns\n",
    "\n",
    "            # Make an optimization step\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Update policy network\n",
    "            loss = (-log_probs * target).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            metrics = {\"Policy Loss\": loss,\n",
    "                       \"Running Reward\": running_reward}\n",
    "            wandb.log({**metrics})\n",
    "\n",
    "            # Render an episode after every 100 policy updates.\n",
    "            if not episode % self.N:\n",
    "                self.policy.eval()\n",
    "                total_reward = 0\n",
    "                total_length = 0\n",
    "                for _ in range(self.M):\n",
    "                    (_, _, _, rewards, length) = self.run_episode(display=True)\n",
    "                    total_reward += np.sum(rewards)\n",
    "                    total_length += length\n",
    "                average_reward = total_reward / self.M\n",
    "                average_rewards.append(average_reward)\n",
    "                print(f'Average Total: {average_reward}')\n",
    "                average_length = total_length / self.M\n",
    "                average_lengths.append(average_length)\n",
    "                print(f'Average Length: {average_length}')\n",
    "\n",
    "                val_metrics = {\"Average Total Reward\": average_reward,\n",
    "                               \"Average Length\": average_length}\n",
    "                wandb.log({**val_metrics})\n",
    "\n",
    "                if average_reward >= best_reward:\n",
    "                    best_reward = average_reward\n",
    "                    state_dict = self.policy.state_dict()\n",
    "\n",
    "                (obs, _, _, _, _) = self.run_episode()\n",
    "                self.policy.train()\n",
    "                print(f'Running reward: {running_rewards[-1]}')\n",
    "\n",
    "        # Return the running rewards.\n",
    "        self.policy.eval()\n",
    "        return (running_rewards, average_rewards, average_lengths, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3668bb3d-fbc9-4e0e-9bab-77a3116a6432",
   "metadata": {
    "id": "3668bb3d-fbc9-4e0e-9bab-77a3116a6432",
    "outputId": "1b101c52-86e7-4668-a8cd-aa58a2fcd54a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_220439-o7h3attu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/o7h3attu' target=\"_blank\">Reinforce without std</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/o7h3attu' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/o7h3attu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with no baseline.\n",
      "Average Total: 21.3\n",
      "Average Length: 21.3\n",
      "Running reward: 0.6497082233428956\n",
      "Average Total: 28.3\n",
      "Average Length: 28.3\n",
      "Running reward: 21.686505653591553\n",
      "Average Total: 26.8\n",
      "Average Length: 26.8\n",
      "Running reward: 24.00807321889379\n",
      "Average Total: 33.4\n",
      "Average Length: 33.4\n",
      "Running reward: 26.99608878710016\n",
      "Average Total: 76.3\n",
      "Average Length: 76.3\n",
      "Running reward: 38.84036962148689\n",
      "Average Total: 67.9\n",
      "Average Length: 67.9\n",
      "Running reward: 44.86376850914731\n",
      "Average Total: 91.8\n",
      "Average Length: 91.8\n",
      "Running reward: 54.97029859122171\n",
      "Average Total: 119.1\n",
      "Average Length: 119.1\n",
      "Running reward: 61.43057535894768\n",
      "Average Total: 83.1\n",
      "Average Length: 83.1\n",
      "Running reward: 59.958023427857206\n",
      "Average Total: 158.1\n",
      "Average Length: 158.1\n",
      "Running reward: 58.74335755000611\n",
      "Average Total: 166.0\n",
      "Average Length: 166.0\n",
      "Running reward: 75.78445376297306\n",
      "Average Total: 165.7\n",
      "Average Length: 165.7\n",
      "Running reward: 76.47119771135021\n",
      "Average Total: 210.4\n",
      "Average Length: 210.4\n",
      "Running reward: 88.09790263492535\n",
      "Average Total: 119.7\n",
      "Average Length: 119.7\n",
      "Running reward: 60.263473828008586\n",
      "Average Total: 224.2\n",
      "Average Length: 224.2\n",
      "Running reward: 76.34931537785873\n",
      "Average Total: 480.6\n",
      "Average Length: 480.6\n",
      "Running reward: 96.47855357729763\n",
      "Average Total: 124.7\n",
      "Average Length: 124.7\n",
      "Running reward: 72.14120743304875\n",
      "Average Total: 124.8\n",
      "Average Length: 124.8\n",
      "Running reward: 84.08899983534448\n",
      "Average Total: 368.0\n",
      "Average Length: 368.0\n",
      "Running reward: 95.37696061447554\n",
      "Average Total: 303.7\n",
      "Average Length: 303.7\n",
      "Running reward: 85.34387113580884\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:o7h3attu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▄▂▄█▃▃▆▅</td></tr><tr><td>Average Total Reward</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▄▂▄█▃▃▆▅</td></tr><tr><td>Policy Loss</td><td>▂▁▆▄▃▄▁▃▅▃▆▃▂▅▃▃▅▅▄▅▇▆▅▅▃▆▆▇▇▄█▇▅▄▆▅▅▆▆▅</td></tr><tr><td>Running Reward</td><td>▁▂▂▂▂▂▂▃▄▄▄▄▄▅▅▄▅▅▆▇▇▆▇█▆▄▆▇▇██▆▇█▇██▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>303.7</td></tr><tr><td>Average Total Reward</td><td>303.7</td></tr><tr><td>Policy Loss</td><td>12.14417</td></tr><tr><td>Running Reward</td><td>84.69919</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce without std</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/o7h3attu' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/o7h3attu</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_220439-o7h3attu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:o7h3attu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_222122-txpr0gy3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/txpr0gy3' target=\"_blank\">Reinforce without std</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/txpr0gy3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/txpr0gy3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with no baseline.\n",
      "Average Total: 25.5\n",
      "Average Length: 25.5\n",
      "Running reward: 0.42808961868286133\n",
      "Average Total: 40.4\n",
      "Average Length: 40.4\n",
      "Running reward: 25.83990490063615\n",
      "Average Total: 20.4\n",
      "Average Length: 20.4\n",
      "Running reward: 18.91481959818454\n",
      "Average Total: 63.8\n",
      "Average Length: 63.8\n",
      "Running reward: 38.63250651648312\n",
      "Average Total: 118.3\n",
      "Average Length: 118.3\n",
      "Running reward: 35.08271682967789\n",
      "Average Total: 108.4\n",
      "Average Length: 108.4\n",
      "Running reward: 59.78177470420637\n",
      "Average Total: 92.5\n",
      "Average Length: 92.5\n",
      "Running reward: 56.27718725531761\n",
      "Average Total: 337.9\n",
      "Average Length: 337.9\n",
      "Running reward: 90.47169477535797\n",
      "Average Total: 470.8\n",
      "Average Length: 470.8\n",
      "Running reward: 85.14311458508297\n",
      "Average Total: 463.5\n",
      "Average Length: 463.5\n",
      "Running reward: 98.06804627883203\n",
      "Average Total: 464.3\n",
      "Average Length: 464.3\n",
      "Running reward: 97.30743683056632\n",
      "Average Total: 478.6\n",
      "Average Length: 478.6\n",
      "Running reward: 96.82032698138853\n",
      "Average Total: 369.1\n",
      "Average Length: 369.1\n",
      "Running reward: 88.15321882734017\n",
      "Average Total: 130.3\n",
      "Average Length: 130.3\n",
      "Running reward: 56.11157382961312\n",
      "Average Total: 201.7\n",
      "Average Length: 201.7\n",
      "Running reward: 77.33691271742077\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.82228695163437\n",
      "Average Total: 490.6\n",
      "Average Length: 490.6\n",
      "Running reward: 97.20169551280847\n",
      "Average Total: 112.3\n",
      "Average Length: 112.3\n",
      "Running reward: 79.07275594646909\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.51748652892755\n",
      "Average Total: 296.0\n",
      "Average Length: 296.0\n",
      "Running reward: 96.61218922466425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:txpr0gy3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▁▂▂▂▂▆█▇▇█▆▃▄██▂█▅</td></tr><tr><td>Average Total Reward</td><td>▁▁▁▂▂▂▂▆█▇▇█▆▃▄██▂█▅</td></tr><tr><td>Policy Loss</td><td>▃▃█▅▂▃▂▃▇▅▇▆▇▆▅▇▄▅▅▅▄▄▄▆▂█▂█▇▄▄▆▄▆▅▃▃▃▂▁</td></tr><tr><td>Running Reward</td><td>▁▂▂▂▂▂▃▂▅▄▅▇▆▇▇▅▇██████▇▆▆▅▅▆████▇▆███▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>296.0</td></tr><tr><td>Average Total Reward</td><td>296.0</td></tr><tr><td>Policy Loss</td><td>3.37506</td></tr><tr><td>Running Reward</td><td>25.6201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce without std</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/txpr0gy3' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/txpr0gy3</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_222122-txpr0gy3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:txpr0gy3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_224858-klmhsyz8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/klmhsyz8' target=\"_blank\">Reinforce without std</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/klmhsyz8' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/klmhsyz8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with no baseline.\n",
      "Average Total: 29.2\n",
      "Average Length: 29.2\n",
      "Running reward: 1.0608932495117187\n",
      "Average Total: 44.9\n",
      "Average Length: 44.9\n",
      "Running reward: 34.353444827513506\n",
      "Average Total: 69.3\n",
      "Average Length: 69.3\n",
      "Running reward: 40.15142466592689\n",
      "Average Total: 98.1\n",
      "Average Length: 98.1\n",
      "Running reward: 57.24275572431227\n",
      "Average Total: 262.1\n",
      "Average Length: 262.1\n",
      "Running reward: 61.67759797621861\n",
      "Average Total: 133.7\n",
      "Average Length: 133.7\n",
      "Running reward: 66.97493610526575\n",
      "Average Total: 120.8\n",
      "Average Length: 120.8\n",
      "Running reward: 75.52974037879046\n",
      "Average Total: 109.9\n",
      "Average Length: 109.9\n",
      "Running reward: 66.67732314014523\n",
      "Average Total: 250.6\n",
      "Average Length: 250.6\n",
      "Running reward: 88.58951810067828\n",
      "Average Total: 47.7\n",
      "Average Length: 47.7\n",
      "Running reward: 49.33560274282194\n",
      "Average Total: 98.7\n",
      "Average Length: 98.7\n",
      "Running reward: 52.27052633196842\n",
      "Average Total: 142.6\n",
      "Average Length: 142.6\n",
      "Running reward: 58.058162675865745\n",
      "Average Total: 16.4\n",
      "Average Length: 16.4\n",
      "Running reward: 28.746371892786815\n",
      "Average Total: 15.3\n",
      "Average Length: 15.3\n",
      "Running reward: 13.265973524041526\n",
      "Average Total: 18.4\n",
      "Average Length: 18.4\n",
      "Running reward: 14.422541323179386\n",
      "Average Total: 179.1\n",
      "Average Length: 179.1\n",
      "Running reward: 72.93815382168275\n",
      "Average Total: 221.8\n",
      "Average Length: 221.8\n",
      "Running reward: 79.37250168280026\n",
      "Average Total: 178.8\n",
      "Average Length: 178.8\n",
      "Running reward: 82.60529504594189\n",
      "Average Total: 172.0\n",
      "Average Length: 172.0\n",
      "Running reward: 76.8121772530101\n",
      "Average Total: 153.0\n",
      "Average Length: 153.0\n",
      "Running reward: 60.18606071721906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:klmhsyz8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▃▃█▄▄▄█▂▃▅▁▁▁▆▇▆▅▅</td></tr><tr><td>Average Total Reward</td><td>▁▂▃▃█▄▄▄█▂▃▅▁▁▁▆▇▆▅▅</td></tr><tr><td>Policy Loss</td><td>▅▇▅▄▅█▆▃▇▄▇▆▅▆▆▅▅▅▁▂▃▄▆▂▁▁▁▁▁▇▂▅▆▅▅▆▁▆▃▃</td></tr><tr><td>Running Reward</td><td>▁▂▃▃▃▄▅▅▆▇▆▇▆▇▆▇█▆▃▂▅▄▆▄▂▁▁▁▂▆▄▆▇▇▇▇▃▄▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>153.0</td></tr><tr><td>Average Total Reward</td><td>153.0</td></tr><tr><td>Policy Loss</td><td>5.74649</td></tr><tr><td>Running Reward</td><td>95.64626</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce without std</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/klmhsyz8' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/klmhsyz8</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_224858-klmhsyz8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:klmhsyz8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_230152-6g1wpa6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6g1wpa6x' target=\"_blank\">Reinforce without std</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6g1wpa6x' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/6g1wpa6x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with no baseline.\n",
      "Average Total: 21.8\n",
      "Average Length: 21.8\n",
      "Running reward: 0.7774312019348145\n",
      "Average Total: 41.1\n",
      "Average Length: 41.1\n",
      "Running reward: 40.98544742669288\n",
      "Average Total: 124.0\n",
      "Average Length: 124.0\n",
      "Running reward: 55.14791072226677\n",
      "Average Total: 21.2\n",
      "Average Length: 21.2\n",
      "Running reward: 23.30424198665057\n",
      "Average Total: 175.0\n",
      "Average Length: 175.0\n",
      "Running reward: 38.85004798271144\n",
      "Average Total: 109.7\n",
      "Average Length: 109.7\n",
      "Running reward: 62.28220807488584\n",
      "Average Total: 96.7\n",
      "Average Length: 96.7\n",
      "Running reward: 62.32258979033018\n",
      "Average Total: 271.8\n",
      "Average Length: 271.8\n",
      "Running reward: 96.40232410734545\n",
      "Average Total: 377.5\n",
      "Average Length: 377.5\n",
      "Running reward: 92.44703943794701\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.30120954885301\n",
      "Average Total: 198.2\n",
      "Average Length: 198.2\n",
      "Running reward: 85.45103502722965\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.9377569785624\n",
      "Average Total: 142.8\n",
      "Average Length: 142.8\n",
      "Running reward: 93.9237067122159\n",
      "Average Total: 113.9\n",
      "Average Length: 113.9\n",
      "Running reward: 61.019412676790736\n",
      "Average Total: 121.0\n",
      "Average Length: 121.0\n",
      "Running reward: 70.50726441755303\n",
      "Average Total: 102.6\n",
      "Average Length: 102.6\n",
      "Running reward: 64.58596955051831\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.37724895619841\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33182064485261\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3494206298339\n",
      "Average Total: 496.0\n",
      "Average Length: 496.0\n",
      "Running reward: 97.86839121392212\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6g1wpa6x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▃▁▃▂▂▅▆█▄█▃▂▂▂████</td></tr><tr><td>Average Total Reward</td><td>▁▁▃▁▃▂▂▅▆█▄█▃▂▂▂████</td></tr><tr><td>Policy Loss</td><td>▄▅▇▃▆▃▁▁▅█▇▅▆▄▆▆▄▄▄▆▆▃▄▄▄▄▃▄▄▅▄▄▃▃▃▄▄▄▄▅</td></tr><tr><td>Running Reward</td><td>▁▃▃▄▅▄▁▁▆▇▅▅▆█▇▇████▇███▇▅▆▆▆▅▅▇███████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>496.0</td></tr><tr><td>Average Total Reward</td><td>496.0</td></tr><tr><td>Policy Loss</td><td>7.00684</td></tr><tr><td>Running Reward</td><td>89.56594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce without std</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/6g1wpa6x' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/6g1wpa6x</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_230152-6g1wpa6x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6g1wpa6x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240511_232852-yjvhtub5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yjvhtub5' target=\"_blank\">Reinforce without std</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yjvhtub5' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/yjvhtub5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with no baseline.\n",
      "Average Total: 19.5\n",
      "Average Length: 19.5\n",
      "Running reward: 0.7774312019348145\n",
      "Average Total: 28.3\n",
      "Average Length: 28.3\n",
      "Running reward: 25.33766506726217\n",
      "Average Total: 32.9\n",
      "Average Length: 32.9\n",
      "Running reward: 32.82942792120509\n",
      "Average Total: 141.1\n",
      "Average Length: 141.1\n",
      "Running reward: 70.90733730692628\n",
      "Average Total: 315.7\n",
      "Average Length: 315.7\n",
      "Running reward: 87.09838858929352\n",
      "Average Total: 83.5\n",
      "Average Length: 83.5\n",
      "Running reward: 70.14015037828108\n",
      "Average Total: 91.5\n",
      "Average Length: 91.5\n",
      "Running reward: 62.87526524960545\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 93.40735237851514\n",
      "Average Total: 489.6\n",
      "Average Length: 489.6\n",
      "Running reward: 98.25662608092652\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.43213824157567\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3440940338763\n",
      "Average Total: 82.3\n",
      "Average Length: 82.3\n",
      "Running reward: 84.32670736503974\n",
      "Average Total: 228.8\n",
      "Average Length: 228.8\n",
      "Running reward: 71.6734046268058\n",
      "Average Total: 125.8\n",
      "Average Length: 125.8\n",
      "Running reward: 63.98789997260447\n",
      "Average Total: 131.7\n",
      "Average Length: 131.7\n",
      "Running reward: 73.59823209240886\n",
      "Average Total: 125.2\n",
      "Average Length: 125.2\n",
      "Running reward: 69.6559657472891\n",
      "Average Total: 70.8\n",
      "Average Length: 70.8\n",
      "Running reward: 53.890750231720396\n",
      "Average Total: 124.9\n",
      "Average Length: 124.9\n",
      "Running reward: 70.20793724846916\n",
      "Average Total: 127.6\n",
      "Average Length: 127.6\n",
      "Running reward: 69.54676262242002\n",
      "Average Total: 255.4\n",
      "Average Length: 255.4\n",
      "Running reward: 88.79783191831157\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    # Instantiate a rendering and a non-rendering environment.\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"Reinforce without std\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"architecture\": \"REINFORCE_STD\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 10,\n",
    "          \"M\": 10,\n",
    "          \"baseline\": None})\n",
    "    \n",
    "    # Make a policy network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "\n",
    "    # Train the agent.\n",
    "    r = ReinforceStd(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"], baseline=run.config[\"baseline\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2113e1-ddf3-4845-9efc-073f0376b627",
   "metadata": {
    "id": "cd2113e1-ddf3-4845-9efc-073f0376b627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 465.1\n",
      "Average reward for episode: 23.55\n",
      "Average reward for episode: 465.55\n",
      "Average reward for episode: 428.95\n",
      "Average reward for episode: 475.05\n",
      "Total Average reward for test episode: 371.64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▁▃▅▂▂████▂▄▃▃▃▂▃▃▄</td></tr><tr><td>Average Total Reward</td><td>▁▁▁▃▅▂▂████▂▄▃▃▃▂▃▃▄</td></tr><tr><td>Policy Loss</td><td>▂▂▆█▁█▅▅▅▇▃▆▃▄▄▄▅▅▄▄▄▄▂▅▆▂▅▃▆▄▄▄▄▅▃▅▄▄▄▂</td></tr><tr><td>Running Reward</td><td>▁▂▂▃▃▄▅▆▇▇▄▄▅▆████████▄▅▇▄▆▆▆▆▆▅▅▆▆▆▇▇██</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>255.4</td></tr><tr><td>Average Total Reward</td><td>255.4</td></tr><tr><td>Policy Loss</td><td>6.49841</td></tr><tr><td>Running Reward</td><td>97.95765</td></tr><tr><td>Total average test reward</td><td>371.64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Reinforce without std</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yjvhtub5' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/yjvhtub5</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240511_232852-yjvhtub5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfde8e-f1c7-4d96-85e0-268f687e09df",
   "metadata": {
    "id": "46cfde8e-f1c7-4d96-85e0-268f687e09df"
   },
   "source": [
    "**The Real Exercise**: Standard practice is to use the state-value function $v(s)$ as a baseline. This is intuitively appealing -- we are more interested in updating out policy for returns that estimate the current **value** worse. Our new update becomes:\n",
    "\n",
    "$$ \\boldsymbol{\\theta}_{t+1} \\triangleq \\boldsymbol{\\theta}_t + \\alpha (G_t - \\tilde{v}(S_t \\mid \\mathbf{w})) \\frac{\\nabla \\pi(A_t \\mid s, \\boldsymbol{\\theta})}{\\pi(A_t \\mid s, \\boldsymbol{\\theta})} $$\n",
    "\n",
    "where $\\tilde{v}(s \\mid \\mathbf{w})$ is a **deep neural network** with parameters $w$ that estimates $v_\\pi(s)$. What neural network? Typically, we use the **same** network architecture as that of the Policy.\n",
    "\n",
    "**Your Task**: Modify your implementation to fit a second, baseline network to estimate the value function and use it as **baseline**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0894204b-726d-4573-b549-ac5406bcde19",
   "metadata": {
    "id": "0894204b-726d-4573-b549-ac5406bcde19"
   },
   "outputs": [],
   "source": [
    "class ReinforceBas(ReinforceStd):\n",
    "    def __init__(self, policy, env, env_render=None, gamma=0.99, num_episodes=10, lr=1e-2,\n",
    "                 max_len=500, N=100, eval_episodes=10, baseline=None, lrb=1e-2):\n",
    "        super().__init__(policy, env, env_render, gamma, num_episodes, lr, \n",
    "                         max_len, N, eval_episodes, baseline)\n",
    "        self.learning_rate_baseline = lrb\n",
    "\n",
    "    def select_action(self, obs):\n",
    "        value = self.baseline(obs)\n",
    "        value.compute_grad = True\n",
    "        dist = Categorical(self.policy(obs))\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return (action.item(), log_prob.reshape(1), value)\n",
    "\n",
    "    # Given an environment and a policy, run it up to the maximum number of steps.\n",
    "    def run_episode(self, display=False, test=False):\n",
    "        # Collect just about everything.\n",
    "        observations = []\n",
    "        actions = []\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        values = []\n",
    "        env = self.environment\n",
    "        if display:\n",
    "            env = self.env_render\n",
    "\n",
    "        # Reset the environment and start the episode.\n",
    "        (obs, info) = env.reset()\n",
    "        for i in range(self.max_len):\n",
    "            # Get the current observation, run the policy and select an action.\n",
    "            obs = torch.tensor(obs)\n",
    "            if test:\n",
    "                (action, log_prob) = self.select_max_action(obs)\n",
    "            else:\n",
    "                (action, log_prob, value) = self.select_action(obs)\n",
    "                values.append(value)\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            log_probs.append(log_prob)\n",
    "\n",
    "            # Advance the episode by executing the selected action.\n",
    "            (obs, reward, term, trunc, info) = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if term or trunc:\n",
    "                break\n",
    "        length = i + 1\n",
    "        return (observations, actions, torch.cat(log_probs), rewards, length, values)\n",
    "\n",
    "    # A direct, inefficient, and probably buggy of the REINFORCE policy gradient algorithm.\n",
    "    def reinforce(self):\n",
    "        # The only non-vanilla part: we use Adam instead of SGD.\n",
    "        opt = torch.optim.Adam(self.policy.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # If we have a baseline network, create the optimizer.\n",
    "        if isinstance(self.baseline, nn.Module):\n",
    "            opt_baseline = torch.optim.Adam(self.baseline.parameters(), lr=self.learning_rate_baseline)\n",
    "            self.baseline.train()\n",
    "            print('Training agent with baseline value network.')\n",
    "        elif self.baseline == 'std':\n",
    "            print('Training agent with standardization baseline.')\n",
    "        else:\n",
    "            print('Training agent with no baseline.')\n",
    "\n",
    "        # Track episode rewards in a list.\n",
    "        running_rewards = [0.0]\n",
    "        average_rewards = []\n",
    "        average_lengths = []\n",
    "\n",
    "        # The main training loop.\n",
    "        self.policy.train()\n",
    "        state_dict = None\n",
    "        best_reward = 0\n",
    "        for episode in range(self.num_episodes):\n",
    "            # Run an episode of the environment, collect everything needed for policy update.\n",
    "            (observations, actions, log_probs, rewards, length, values) = self.run_episode()\n",
    "\n",
    "            # Compute the discounted reward for every step of the episode.\n",
    "            returns = torch.tensor(self.compute_returns(rewards), dtype=torch.float32)\n",
    "            values =  torch.cat(values)\n",
    "\n",
    "            # Keep a running average of total discounted rewards for the whole episode.\n",
    "            running_reward = 0.05 * returns[0] + 0.95 * running_rewards[-1]\n",
    "            wandb.log({\"Reward\": running_reward})\n",
    "            running_rewards.append(running_reward)\n",
    "\n",
    "            # Handle baseline.\n",
    "            if isinstance(self.baseline, nn.Module):\n",
    "                with torch.no_grad():\n",
    "                    target = returns - values\n",
    "            elif self.baseline == 'std':\n",
    "                target = (returns - returns.mean()) / returns.std()\n",
    "            else:\n",
    "                target = returns\n",
    "\n",
    "            # Make an optimization step\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Update policy network\n",
    "            loss = (-log_probs * target).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Update baseline network.\n",
    "            if isinstance(self.baseline, nn.Module):\n",
    "                loss_baseline = F.mse_loss(values, returns)\n",
    "                wandb.log({\"Loss_baseline\": loss_baseline})\n",
    "                opt_baseline.zero_grad()\n",
    "                loss_baseline.backward()\n",
    "                opt_baseline.step()\n",
    "\n",
    "                metrics = {\"Policy Loss\": loss,\n",
    "                           \"Running Reward\": running_reward,\n",
    "                           \"Baseline Loss\": loss_baseline}\n",
    "            else:\n",
    "              metrics = {\"Policy Loss\": loss,\n",
    "                         \"Running Reward\": running_reward}\n",
    "\n",
    "            wandb.log({**metrics})\n",
    "\n",
    "            # Render an episode after every 100 policy updates.\n",
    "            if not episode % self.N:\n",
    "                self.policy.eval()\n",
    "                total_reward = 0\n",
    "                total_length = 0\n",
    "                for _ in range(self.M):\n",
    "                    (_, _, _, rewards, length, values) = self.run_episode()\n",
    "                    total_reward += np.sum(rewards)\n",
    "                    total_length += length\n",
    "                average_reward = total_reward / self.M\n",
    "                wandb.log({\"Avg_total_reward\": average_reward})\n",
    "                average_rewards.append(average_reward)\n",
    "                print(f'Average Total: {average_reward}')\n",
    "                average_length = total_length / self.M\n",
    "                wandb.log({\"Avg_length\": average_length})\n",
    "                average_lengths.append(average_length)\n",
    "                print(f'Average Length: {average_length}')\n",
    "\n",
    "                val_metrics = {\"Average Total Reward\": average_reward,\n",
    "                               \"Average Length\": average_length}\n",
    "                wandb.log({**val_metrics})\n",
    "\n",
    "                if average_reward >= best_reward:\n",
    "                    best_reward = average_reward\n",
    "                    state_dict = self.policy.state_dict()\n",
    "\n",
    "                (obs, _, _, _, _, _) = self.run_episode(display=True)\n",
    "                self.policy.train()\n",
    "                print(f'Running reward: {running_rewards[-1]}')\n",
    "\n",
    "        # Return the running rewards.\n",
    "        self.policy.eval()\n",
    "        if isinstance(self.baseline, nn.Module):\n",
    "            self.baseline.eval()\n",
    "        return (running_rewards, average_rewards, average_lengths, state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f68237",
   "metadata": {},
   "source": [
    "Runs varying learning_rate and hidden_layer_size for baseline net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f22722-e8f5-4ced-9614-1f4778d3e981",
   "metadata": {
    "id": "46f22722-e8f5-4ced-9614-1f4778d3e981",
    "outputId": "79bc023d-7cd0-44d6-81b3-6c9a6b1c392d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_000335-07vpszto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/07vpszto' target=\"_blank\">ReinforceBas</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/07vpszto' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/07vpszto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 19.8\n",
      "Average Length: 19.8\n",
      "Running reward: 0.9013606905937195\n",
      "Average Total: 125.4\n",
      "Average Length: 125.4\n",
      "Running reward: 45.96234893798828\n",
      "Average Total: 259.2\n",
      "Average Length: 259.2\n",
      "Running reward: 89.23333740234375\n",
      "Average Total: 481.3\n",
      "Average Length: 481.3\n",
      "Running reward: 95.04817199707031\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.9099349975586\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34683227539062\n",
      "Average Total: 333.2\n",
      "Average Length: 333.2\n",
      "Running reward: 93.80870056152344\n",
      "Average Total: 499.0\n",
      "Average Length: 499.0\n",
      "Running reward: 97.20504760742188\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34073638916016\n",
      "Average Total: 427.5\n",
      "Average Length: 427.5\n",
      "Running reward: 98.03227996826172\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34623718261719\n",
      "Average Total: 459.9\n",
      "Average Length: 459.9\n",
      "Running reward: 98.0577621459961\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.12035369873047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33030700683594\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34931182861328\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 490.9\n",
      "Average Length: 490.9\n",
      "Running reward: 97.32872772216797\n",
      "Average Total: 312.2\n",
      "Average Length: 312.2\n",
      "Running reward: 96.2330551147461\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.22257232666016\n",
      "Average Total: 317.2\n",
      "Average Length: 317.2\n",
      "Running reward: 89.65352630615234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:07vpszto) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▃▄███▆██▇█▇█████▅█▅</td></tr><tr><td>Average Total Reward</td><td>▁▃▄███▆██▇█▇█████▅█▅</td></tr><tr><td>Avg_length</td><td>▁▃▄███▆██▇█▇█████▅█▅</td></tr><tr><td>Avg_total_reward</td><td>▁▃▄███▆██▇█▇█████▅█▅</td></tr><tr><td>Baseline Loss</td><td>▁▂▇█▃▄██▇▄▅▂▂▃▁▁▆▆▅▇▇▇▃▃▇▃▇▇▇▇▆▄▆▆▅█▃▃▆▅</td></tr><tr><td>Loss_baseline</td><td>▁▂▇█▃▄██▇▄▅▂▂▃▁▁▆▆▅▇▇▇▃▃▇▃▇▇▇▇▆▄▆▆▅█▃▃▆▅</td></tr><tr><td>Policy Loss</td><td>▅▄▇▆▅▅▅▁▅▆▅▅▆▂▄▄▃▃▆▆▄▄▅▅▇▅▅▅▄▄▅▅▄▇▂█▃▅▄▄</td></tr><tr><td>Reward</td><td>▁▂▄▇▇▇██████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▄▇▇▇██████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>317.2</td></tr><tr><td>Average Total Reward</td><td>317.2</td></tr><tr><td>Avg_length</td><td>317.2</td></tr><tr><td>Avg_total_reward</td><td>317.2</td></tr><tr><td>Baseline Loss</td><td>331.57318</td></tr><tr><td>Loss_baseline</td><td>331.57318</td></tr><tr><td>Policy Loss</td><td>0.29328</td></tr><tr><td>Reward</td><td>98.2318</td></tr><tr><td>Running Reward</td><td>98.2318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/07vpszto' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/07vpszto</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_000335-07vpszto\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:07vpszto). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_002751-i5nilo3l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5nilo3l' target=\"_blank\">ReinforceBas</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5nilo3l' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/i5nilo3l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 21.8\n",
      "Average Length: 21.8\n",
      "Running reward: 0.6927111744880676\n",
      "Average Total: 93.7\n",
      "Average Length: 93.7\n",
      "Running reward: 49.437034606933594\n",
      "Average Total: 463.5\n",
      "Average Length: 463.5\n",
      "Running reward: 94.8961410522461\n",
      "Average Total: 471.3\n",
      "Average Length: 471.3\n",
      "Running reward: 97.31956481933594\n",
      "Average Total: 467.3\n",
      "Average Length: 467.3\n",
      "Running reward: 98.16445922851562\n",
      "Average Total: 269.2\n",
      "Average Length: 269.2\n",
      "Running reward: 97.17326354980469\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.28874969482422\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34907531738281\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34005737304688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34847259521484\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.23775482177734\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34877014160156\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.21357727050781\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32648468017578\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.27932739257812\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33717346191406\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.18347930908203\n",
      "Average Total: 481.0\n",
      "Average Length: 481.0\n",
      "Running reward: 97.97820281982422\n",
      "Average Total: 488.1\n",
      "Average Length: 488.1\n",
      "Running reward: 97.48698425292969\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.30768585205078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:i5nilo3l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▇██▅██████████████</td></tr><tr><td>Average Total Reward</td><td>▁▂▇██▅██████████████</td></tr><tr><td>Avg_length</td><td>▁▂▇██▅██████████████</td></tr><tr><td>Avg_total_reward</td><td>▁▂▇██▅██████████████</td></tr><tr><td>Baseline Loss</td><td>▃▃▄▂▃█▂▄▃█▁▂▂▁▃▂▄▂▁▁▁▁▁▂▁▄▁▁▃▂▁▃▇▄▂▁▁▁▂▂</td></tr><tr><td>Loss_baseline</td><td>▃▃▄▂▃█▂▄▃█▁▂▂▁▃▂▄▂▁▁▁▁▁▂▁▄▁▁▃▂▁▃▇▄▂▁▁▁▂▂</td></tr><tr><td>Policy Loss</td><td>▇▆▁▆▆█▅▅▄▄▄▄▆▅▃▆▇▆▆▄▄▅▅▅▄▇▄▅▃▄▅▆▇▄▄▄▅▅▄▃</td></tr><tr><td>Reward</td><td>▁▃▅▇████████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▃▅▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>16.47844</td></tr><tr><td>Loss_baseline</td><td>16.47844</td></tr><tr><td>Policy Loss</td><td>-0.97385</td></tr><tr><td>Reward</td><td>98.03937</td></tr><tr><td>Running Reward</td><td>98.03937</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5nilo3l' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/i5nilo3l</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_002751-i5nilo3l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:i5nilo3l). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_005303-krjc6uw7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/krjc6uw7' target=\"_blank\">ReinforceBas</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/krjc6uw7' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/krjc6uw7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 22.7\n",
      "Average Length: 22.7\n",
      "Running reward: 1.5372270345687866\n",
      "Average Total: 123.0\n",
      "Average Length: 123.0\n",
      "Running reward: 46.47514343261719\n",
      "Average Total: 446.3\n",
      "Average Length: 446.3\n",
      "Running reward: 94.68729400634766\n",
      "Average Total: 232.8\n",
      "Average Length: 232.8\n",
      "Running reward: 92.20755767822266\n",
      "Average Total: 498.0\n",
      "Average Length: 498.0\n",
      "Running reward: 96.64935302734375\n",
      "Average Total: 479.9\n",
      "Average Length: 479.9\n",
      "Running reward: 96.86875915527344\n",
      "Average Total: 497.3\n",
      "Average Length: 497.3\n",
      "Running reward: 98.23246765136719\n",
      "Average Total: 303.1\n",
      "Average Length: 303.1\n",
      "Running reward: 97.73979949951172\n",
      "Average Total: 481.8\n",
      "Average Length: 481.8\n",
      "Running reward: 98.28963470458984\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.31915283203125\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.51057434082031\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32536315917969\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.58226013183594\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34489440917969\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.33953094482422\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33753204345703\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:krjc6uw7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▇▄███▅████████████</td></tr><tr><td>Average Total Reward</td><td>▁▂▇▄███▅████████████</td></tr><tr><td>Avg_length</td><td>▁▂▇▄███▅████████████</td></tr><tr><td>Avg_total_reward</td><td>▁▂▇▄███▅████████████</td></tr><tr><td>Baseline Loss</td><td>▁▁▇▃▄▂▃▇▃▂▇▅▃▂▂▄▂▃▂▁▂▂▁▁▁▂▁▂▁▁▂█▃▂▁▁▁▂▁▄</td></tr><tr><td>Loss_baseline</td><td>▁▁▇▃▄▂▃▇▃▂▇▅▃▂▂▄▂▃▂▁▂▂▁▁▁▂▁▂▁▁▂█▃▂▁▁▁▂▁▄</td></tr><tr><td>Policy Loss</td><td>▅▄▃▃▄▄▄▁▆▄▁▄▇▅▃▆▅▃▆▅▄▃▃▅▄▂▄▅▅▄▅█▅▆▄▄▄▅▄▁</td></tr><tr><td>Reward</td><td>▁▂▅▇██▇███████████▇█████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▅▇██▇███████████▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>536.85193</td></tr><tr><td>Loss_baseline</td><td>536.85193</td></tr><tr><td>Policy Loss</td><td>0.66678</td></tr><tr><td>Reward</td><td>98.34936</td></tr><tr><td>Running Reward</td><td>98.34936</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/krjc6uw7' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/krjc6uw7</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_005303-krjc6uw7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:krjc6uw7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_011720-8zln1fiw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/8zln1fiw' target=\"_blank\">ReinforceBas</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/8zln1fiw' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/8zln1fiw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 20.3\n",
      "Average Length: 20.3\n",
      "Running reward: 1.1382864713668823\n",
      "Average Total: 165.1\n",
      "Average Length: 165.1\n",
      "Running reward: 50.45021057128906\n",
      "Average Total: 475.9\n",
      "Average Length: 475.9\n",
      "Running reward: 95.73809814453125\n",
      "Average Total: 384.8\n",
      "Average Length: 384.8\n",
      "Running reward: 88.25031280517578\n",
      "Average Total: 469.2\n",
      "Average Length: 469.2\n",
      "Running reward: 94.30438995361328\n",
      "Average Total: 432.8\n",
      "Average Length: 432.8\n",
      "Running reward: 97.99562072753906\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.11251831054688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.69313049316406\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.94505310058594\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.95350646972656\n",
      "Average Total: 469.4\n",
      "Average Length: 469.4\n",
      "Running reward: 98.31255340576172\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.25164031982422\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3488540649414\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.1761245727539\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34840393066406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8zln1fiw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▃█▆█▇██████████████</td></tr><tr><td>Average Total Reward</td><td>▁▃█▆█▇██████████████</td></tr><tr><td>Avg_length</td><td>▁▃█▆█▇██████████████</td></tr><tr><td>Avg_total_reward</td><td>▁▃█▆█▇██████████████</td></tr><tr><td>Baseline Loss</td><td>▁▂▃▃█▂▂▂▄▄▂▄▂▃▃▁▄▆▅▅▂▃▃▅▄▄▂▂▂▂▃▃▁▁▁▁▆▅▃▂</td></tr><tr><td>Loss_baseline</td><td>▁▂▃▃█▂▂▂▄▄▂▄▂▃▃▁▄▆▅▅▂▃▃▅▄▄▂▂▂▂▃▃▁▁▁▁▆▅▃▂</td></tr><tr><td>Policy Loss</td><td>▅▅▅▃█▆▅▄▂▄▅▃▄▁▅▄▁▅▃▂▃▃▆▆▄▅▅▅▅▃▃▂▃▅▄▄▄▄▄▅</td></tr><tr><td>Reward</td><td>▁▂▅▇████████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▅▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>205.38142</td></tr><tr><td>Loss_baseline</td><td>205.38142</td></tr><tr><td>Policy Loss</td><td>2.27979</td></tr><tr><td>Reward</td><td>98.34936</td></tr><tr><td>Running Reward</td><td>98.34936</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/8zln1fiw' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/8zln1fiw</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_011720-8zln1fiw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8zln1fiw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_014223-okaqbedw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/okaqbedw' target=\"_blank\">ReinforceBas</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/okaqbedw' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/okaqbedw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 19.9\n",
      "Average Length: 19.9\n",
      "Running reward: 0.8604653477668762\n",
      "Average Total: 157.3\n",
      "Average Length: 157.3\n",
      "Running reward: 56.816139221191406\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.77999114990234\n",
      "Average Total: 476.7\n",
      "Average Length: 476.7\n",
      "Running reward: 97.58685302734375\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.23280334472656\n",
      "Average Total: 486.2\n",
      "Average Length: 486.2\n",
      "Running reward: 98.34669494628906\n",
      "Average Total: 314.2\n",
      "Average Length: 314.2\n",
      "Running reward: 90.81932830810547\n",
      "Average Total: 487.1\n",
      "Average Length: 487.1\n",
      "Running reward: 98.28250885009766\n",
      "Average Total: 477.5\n",
      "Average Length: 477.5\n",
      "Running reward: 98.3460464477539\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34691619873047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33350372314453\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 94.72212982177734\n",
      "Average Total: 479.7\n",
      "Average Length: 479.7\n",
      "Running reward: 97.64630126953125\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32795715332031\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34929656982422\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33260345458984\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34260559082031\n",
      "Average Total: 425.8\n",
      "Average Length: 425.8\n",
      "Running reward: 97.0655517578125\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.73773956298828\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.10305786132812\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    # Instantiate a rendering and a non-rendering environment.\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"ReinforceBas\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"baaseline_learning_rate\":1e-2,\n",
    "          \"architecture\": \"REINFORCE_BAS\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 10,\n",
    "          \"M\": 10,\n",
    "          \"baseline\": \"BaselineNet\",\n",
    "          \"learning_rate_baseline\": 1e-2})\n",
    "\n",
    "    # Make a policy and a baseline network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "    baseline = BaselineNet(env)\n",
    "\n",
    "    # Train the agent.r = ReinforceBas(policy, env, env_render, num_episodes=2000, baseline=baseline)\n",
    "    r = ReinforceBas(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"], baseline=baseline,\n",
    "                     lrb=run.config[\"learning_rate_baseline\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27c90b54-c5bb-4fea-b6ee-feff1c94253b",
   "metadata": {
    "id": "27c90b54-c5bb-4fea-b6ee-feff1c94253b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 500.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▃████▅██████████▇██</td></tr><tr><td>Average Total Reward</td><td>▁▃████▅██████████▇██</td></tr><tr><td>Avg_length</td><td>▁▃████▅██████████▇██</td></tr><tr><td>Avg_total_reward</td><td>▁▃████▅██████████▇██</td></tr><tr><td>Baseline Loss</td><td>▁▁▄▄▄▂▃▇▇▅▅▁▃▅▅▅▆▄▃▁▄▃▄▂▂▃▂▆▃▄▃▃█▆▁█▅▄▅▃</td></tr><tr><td>Loss_baseline</td><td>▁▁▄▄▄▂▃▇▇▅▅▁▃▅▅▅▆▄▃▁▄▃▄▂▂▃▂▆▃▄▃▃█▆▁█▅▄▅▃</td></tr><tr><td>Policy Loss</td><td>█▄▇▇▄▆▃█▅▇▅▆▅▄▅▅▆▆▅▆▃▆▅▆▅▅▆▁▅▅▅▄▂█▅▃▆▄▆▆</td></tr><tr><td>Reward</td><td>▁▃▆▇███████▇████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▃▆▇███████▇████████████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>133.73801</td></tr><tr><td>Loss_baseline</td><td>133.73801</td></tr><tr><td>Policy Loss</td><td>-0.54477</td></tr><tr><td>Reward</td><td>98.33543</td></tr><tr><td>Running Reward</td><td>98.33543</td></tr><tr><td>Total average test reward</td><td>500.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/okaqbedw' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/okaqbedw</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_014223-okaqbedw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4de665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_095524-yc1ye8gk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yc1ye8gk' target=\"_blank\">ReinforceBas lower inner_size</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yc1ye8gk' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/yc1ye8gk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 17.0\n",
      "Average Length: 17.0\n",
      "Running reward: 0.4733087122440338\n",
      "Average Total: 50.6\n",
      "Average Length: 50.6\n",
      "Running reward: 32.35449981689453\n",
      "Average Total: 333.3\n",
      "Average Length: 333.3\n",
      "Running reward: 79.63274383544922\n",
      "Average Total: 496.4\n",
      "Average Length: 496.4\n",
      "Running reward: 96.70327758789062\n",
      "Average Total: 447.5\n",
      "Average Length: 447.5\n",
      "Running reward: 96.91535186767578\n",
      "Average Total: 460.3\n",
      "Average Length: 460.3\n",
      "Running reward: 98.22537231445312\n",
      "Average Total: 490.1\n",
      "Average Length: 490.1\n",
      "Running reward: 97.33820343017578\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 94.5257339477539\n",
      "Average Total: 169.5\n",
      "Average Length: 169.5\n",
      "Running reward: 81.21688842773438\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.94082641601562\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34701538085938\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.27505493164062\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34899139404297\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.23614501953125\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.28257751464844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yc1ye8gk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▁▆█▇▇██▃███████████</td></tr><tr><td>Average Total Reward</td><td>▁▁▆█▇▇██▃███████████</td></tr><tr><td>Avg_length</td><td>▁▁▆█▇▇██▃███████████</td></tr><tr><td>Avg_total_reward</td><td>▁▁▆█▇▇██▃███████████</td></tr><tr><td>Baseline Loss</td><td>▂▁▂▁█▃▅▃▂▁▂▄▂▁▅▁▁▃▆▃▁▂▁▆▅▃▇▃▁▂▁▁▁▁▄▃▂▂▁▂</td></tr><tr><td>Loss_baseline</td><td>▂▁▂▁█▃▅▃▂▁▂▄▂▁▅▁▁▃▆▃▁▂▁▆▅▃▇▃▁▂▁▁▁▁▄▃▂▂▁▂</td></tr><tr><td>Policy Loss</td><td>▅▄▃▃▆▆█▅▅▄▃▃▃▄▁▅▄▃▄▆▃▂▄▅▄▄▂▆▄▂▄▄▅▃▂▅▄▃▃▄</td></tr><tr><td>Reward</td><td>▁▂▃▅▇████████▇█▇▇███████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▃▅▇████████▇█▇▇███████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>267.01199</td></tr><tr><td>Loss_baseline</td><td>267.01199</td></tr><tr><td>Policy Loss</td><td>-0.40022</td></tr><tr><td>Reward</td><td>98.34526</td></tr><tr><td>Running Reward</td><td>98.34526</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas lower inner_size</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/yc1ye8gk' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/yc1ye8gk</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_095524-yc1ye8gk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yc1ye8gk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_101812-i5b9tfwg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5b9tfwg' target=\"_blank\">ReinforceBas lower inner_size</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5b9tfwg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/i5b9tfwg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 20.5\n",
      "Average Length: 20.5\n",
      "Running reward: 0.6497082114219666\n",
      "Average Total: 73.5\n",
      "Average Length: 73.5\n",
      "Running reward: 31.853710174560547\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 87.5874252319336\n",
      "Average Total: 474.1\n",
      "Average Length: 474.1\n",
      "Running reward: 96.6775131225586\n",
      "Average Total: 455.1\n",
      "Average Length: 455.1\n",
      "Running reward: 97.29200744628906\n",
      "Average Total: 454.2\n",
      "Average Length: 454.2\n",
      "Running reward: 97.34679412841797\n",
      "Average Total: 358.2\n",
      "Average Length: 358.2\n",
      "Running reward: 92.523193359375\n",
      "Average Total: 448.0\n",
      "Average Length: 448.0\n",
      "Running reward: 97.01289367675781\n",
      "Average Total: 223.1\n",
      "Average Length: 223.1\n",
      "Running reward: 90.32347106933594\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.16915130615234\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.20433044433594\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.28092193603516\n",
      "Average Total: 481.0\n",
      "Average Length: 481.0\n",
      "Running reward: 97.64927673339844\n",
      "Average Total: 417.9\n",
      "Average Length: 417.9\n",
      "Running reward: 98.02605438232422\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.31136322021484\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34921264648438\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 489.6\n",
      "Average Length: 489.6\n",
      "Running reward: 98.31206512451172\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.29344177246094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:i5b9tfwg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂██▇▇▆▇▄████▇██████</td></tr><tr><td>Average Total Reward</td><td>▁▂██▇▇▆▇▄████▇██████</td></tr><tr><td>Avg_length</td><td>▁▂██▇▇▆▇▄████▇██████</td></tr><tr><td>Avg_total_reward</td><td>▁▂██▇▇▆▇▄████▇██████</td></tr><tr><td>Baseline Loss</td><td>▁▂▁▂▂▆▃▃▃▄▄▂▃▂▂▁▂▅▄▂▂▂▂▂▁▁▁▁▁▁▁▄▁▁▁▁█▃▂▂</td></tr><tr><td>Loss_baseline</td><td>▁▂▁▂▂▆▃▃▃▄▄▂▃▂▂▁▂▅▄▂▂▂▂▂▁▁▁▁▁▁▁▄▁▁▁▁█▃▂▂</td></tr><tr><td>Policy Loss</td><td>▅▅▄▄▅█▆▄▃▃▄▄▃▅▅▄▃▄▃▄▆▄▄▅▃▄▅▄▄▄▄▅▄▄▄▄▁▄▄▅</td></tr><tr><td>Reward</td><td>▁▂▃▆▇███████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▃▆▇███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>96.8741</td></tr><tr><td>Loss_baseline</td><td>96.8741</td></tr><tr><td>Policy Loss</td><td>-2.06757</td></tr><tr><td>Reward</td><td>98.34908</td></tr><tr><td>Running Reward</td><td>98.34908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas lower inner_size</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/i5b9tfwg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/i5b9tfwg</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_101812-i5b9tfwg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:i5b9tfwg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_104122-tfcp6w9u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/tfcp6w9u' target=\"_blank\">ReinforceBas lower inner_size</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/tfcp6w9u' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/tfcp6w9u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 22.2\n",
      "Average Length: 22.2\n",
      "Running reward: 1.432761549949646\n",
      "Average Total: 64.4\n",
      "Average Length: 64.4\n",
      "Running reward: 31.198293685913086\n",
      "Average Total: 324.9\n",
      "Average Length: 324.9\n",
      "Running reward: 86.25784301757812\n",
      "Average Total: 494.7\n",
      "Average Length: 494.7\n",
      "Running reward: 96.1632308959961\n",
      "Average Total: 439.8\n",
      "Average Length: 439.8\n",
      "Running reward: 94.91915893554688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.54084014892578\n",
      "Average Total: 404.8\n",
      "Average Length: 404.8\n",
      "Running reward: 98.01779174804688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.94641876220703\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.72764587402344\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.11595916748047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.94359588623047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34589385986328\n",
      "Average Total: 469.9\n",
      "Average Length: 469.9\n",
      "Running reward: 97.39584350585938\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.25785064697266\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34876251220703\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 206.4\n",
      "Average Length: 206.4\n",
      "Running reward: 87.8971176147461\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.46347045898438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tfcp6w9u) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▅█▇█▇███████████▄█</td></tr><tr><td>Average Total Reward</td><td>▁▂▅█▇█▇███████████▄█</td></tr><tr><td>Avg_length</td><td>▁▂▅█▇█▇███████████▄█</td></tr><tr><td>Avg_total_reward</td><td>▁▂▅█▇█▇███████████▄█</td></tr><tr><td>Baseline Loss</td><td>▁▂▁▃▃▅▃▆█▂█▄▂▅▃▄▆▇▆▆▆▆▆▂▃▄▆▆▄▆▆▄▅▃▂▁▁▂▂▂</td></tr><tr><td>Loss_baseline</td><td>▁▂▁▃▃▅▃▆█▂█▄▂▅▃▄▆▇▆▆▆▆▆▂▃▄▆▆▄▆▆▄▅▃▂▁▁▂▂▂</td></tr><tr><td>Policy Loss</td><td>▇▇▄▅█▆▅▅▁▆▃▄▅▄▂▄▄▅▄▇▆▅▃▅▅▆▃▆▅▃▆▇▃▇▇▅▃▃▅▇</td></tr><tr><td>Reward</td><td>▁▂▃▆▇████▇█████████████████████████▇▇███</td></tr><tr><td>Running Reward</td><td>▁▂▃▆▇████▇█████████████████████████▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>96.83517</td></tr><tr><td>Loss_baseline</td><td>96.83517</td></tr><tr><td>Policy Loss</td><td>-1.57884</td></tr><tr><td>Reward</td><td>98.30106</td></tr><tr><td>Running Reward</td><td>98.30106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas lower inner_size</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/tfcp6w9u' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/tfcp6w9u</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_104122-tfcp6w9u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tfcp6w9u). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_110420-c5eo9w0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c5eo9w0q' target=\"_blank\">ReinforceBas lower inner_size</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c5eo9w0q' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c5eo9w0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 24.2\n",
      "Average Length: 24.2\n",
      "Running reward: 1.736941933631897\n",
      "Average Total: 59.0\n",
      "Average Length: 59.0\n",
      "Running reward: 39.15964126586914\n",
      "Average Total: 361.1\n",
      "Average Length: 361.1\n",
      "Running reward: 81.53880310058594\n",
      "Average Total: 402.3\n",
      "Average Length: 402.3\n",
      "Running reward: 96.61164855957031\n",
      "Average Total: 453.0\n",
      "Average Length: 453.0\n",
      "Running reward: 98.05730438232422\n",
      "Average Total: 431.3\n",
      "Average Length: 431.3\n",
      "Running reward: 96.02603912353516\n",
      "Average Total: 366.1\n",
      "Average Length: 366.1\n",
      "Running reward: 97.140625\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 94.53871154785156\n",
      "Average Total: 493.9\n",
      "Average Length: 493.9\n",
      "Running reward: 98.27022552490234\n",
      "Average Total: 282.2\n",
      "Average Length: 282.2\n",
      "Running reward: 97.60303497314453\n",
      "Average Total: 457.1\n",
      "Average Length: 457.1\n",
      "Running reward: 96.67610168457031\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.06002807617188\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34771728515625\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.9725570678711\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.3140640258789\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.07025909423828\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.30537414550781\n",
      "Average Total: 329.8\n",
      "Average Length: 329.8\n",
      "Running reward: 96.32512664794922\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.28711700439453\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34906005859375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:c5eo9w0q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▆▇▇▇▆██▅▇██████▅██</td></tr><tr><td>Average Total Reward</td><td>▁▂▆▇▇▇▆██▅▇██████▅██</td></tr><tr><td>Avg_length</td><td>▁▂▆▇▇▇▆██▅▇██████▅██</td></tr><tr><td>Avg_total_reward</td><td>▁▂▆▇▇▇▆██▅▇██████▅██</td></tr><tr><td>Baseline Loss</td><td>▅▂▃▃▃▆▄█▃▄▃▃▂▁▂▅█▆▃▅▂▂▂▃▄▁▁▁▂▁▁▁▁▁▁▁▃▁▁▇</td></tr><tr><td>Loss_baseline</td><td>▅▂▃▃▃▆▄█▃▄▃▃▂▁▂▅█▆▃▅▂▂▂▃▄▁▁▁▂▁▁▁▁▁▁▁▃▁▁▇</td></tr><tr><td>Policy Loss</td><td>█▂▅▄▃▂▂▁▄▆▂▁▄▂▃▇▄▆▄▄▃▄▂▂▆▃▄▃▄▂▃▃▄▄▄▃▅▂▃▄</td></tr><tr><td>Reward</td><td>▁▃▃▄▇███████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▃▃▄▇███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>646.85034</td></tr><tr><td>Loss_baseline</td><td>646.85034</td></tr><tr><td>Policy Loss</td><td>3.74032</td></tr><tr><td>Reward</td><td>98.34936</td></tr><tr><td>Running Reward</td><td>98.34936</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas lower inner_size</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c5eo9w0q' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c5eo9w0q</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_110420-c5eo9w0q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:c5eo9w0q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_112644-b0ez5isg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b0ez5isg' target=\"_blank\">ReinforceBas lower inner_size</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b0ez5isg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/b0ez5isg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 17.4\n",
      "Average Length: 17.4\n",
      "Running reward: 0.81915682554245\n",
      "Average Total: 76.6\n",
      "Average Length: 76.6\n",
      "Running reward: 32.222686767578125\n",
      "Average Total: 373.9\n",
      "Average Length: 373.9\n",
      "Running reward: 92.16215515136719\n",
      "Average Total: 454.1\n",
      "Average Length: 454.1\n",
      "Running reward: 96.19007873535156\n",
      "Average Total: 107.9\n",
      "Average Length: 107.9\n",
      "Running reward: 81.78004455566406\n",
      "Average Total: 369.6\n",
      "Average Length: 369.6\n",
      "Running reward: 90.45332336425781\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.94478607177734\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.40885925292969\n",
      "Average Total: 477.2\n",
      "Average Length: 477.2\n",
      "Running reward: 96.87308502197266\n",
      "Average Total: 442.1\n",
      "Average Length: 442.1\n",
      "Running reward: 97.55530548095703\n",
      "Average Total: 344.0\n",
      "Average Length: 344.0\n",
      "Running reward: 97.45919799804688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.24307250976562\n",
      "Average Total: 485.8\n",
      "Average Length: 485.8\n",
      "Running reward: 97.85135650634766\n",
      "Average Total: 446.3\n",
      "Average Length: 446.3\n",
      "Running reward: 97.8079833984375\n",
      "Average Total: 412.2\n",
      "Average Length: 412.2\n",
      "Running reward: 96.36115264892578\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.29978942871094\n",
      "Average Total: 391.0\n",
      "Average Length: 391.0\n",
      "Running reward: 94.06393432617188\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.2701187133789\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.30998992919922\n",
      "Average Total: 333.8\n",
      "Average Length: 333.8\n",
      "Running reward: 97.30620574951172\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    # Instantiate a rendering and a non-rendering environment.\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"ReinforceBas lower inner_size\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"baaseline_learning_rate\":1e-2,\n",
    "          \"architecture\": \"REINFORCE_BAS\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 64,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 10,\n",
    "          \"M\": 10,\n",
    "          \"baseline\": \"BaselineNet\",\n",
    "          \"learning_rate_baseline\": 1e-2})\n",
    "\n",
    "    # Make a policy and a baseline network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "    baseline = BaselineNet(env)\n",
    "\n",
    "    # Train the agent.r = ReinforceBas(policy, env, env_render, num_episodes=2000, baseline=baseline)\n",
    "    r = ReinforceBas(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"], baseline=baseline,\n",
    "                     lrb=run.config[\"learning_rate_baseline\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4883801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 500.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▆▇▂▆███▇▆██▇▇█▆██▆</td></tr><tr><td>Average Total Reward</td><td>▁▂▆▇▂▆███▇▆██▇▇█▆██▆</td></tr><tr><td>Avg_length</td><td>▁▂▆▇▂▆███▇▆██▇▇█▆██▆</td></tr><tr><td>Avg_total_reward</td><td>▁▂▆▇▂▆███▇▆██▇▇█▆██▆</td></tr><tr><td>Baseline Loss</td><td>▁▂▄▃▄▂▄▆▂▃▃▆▃▁▄▂▆▅▅▅▄▅█▅▂▂▄█▁▃▂▄▃▁▂▁▁▃▂▁</td></tr><tr><td>Loss_baseline</td><td>▁▂▄▃▄▂▄▆▂▃▃▆▃▁▄▂▆▅▅▅▄▅█▅▂▂▄█▁▃▂▄▃▁▂▁▁▃▂▁</td></tr><tr><td>Policy Loss</td><td>▇▇▆▆▆▄▄▆▄▄▅▄█▄▂▄▄▇▅▆▇▃▄▂▇▄▃▁▆▅▆█▅▆▆▄▅▇▇▃</td></tr><tr><td>Reward</td><td>▁▂▃▆▇▇██▆▇██████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▃▆▇▇██▆▇██████████████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>333.8</td></tr><tr><td>Average Total Reward</td><td>333.8</td></tr><tr><td>Avg_length</td><td>333.8</td></tr><tr><td>Avg_total_reward</td><td>333.8</td></tr><tr><td>Baseline Loss</td><td>40.10471</td></tr><tr><td>Loss_baseline</td><td>40.10471</td></tr><tr><td>Policy Loss</td><td>0.88201</td></tr><tr><td>Reward</td><td>98.2653</td></tr><tr><td>Running Reward</td><td>98.2653</td></tr><tr><td>Total average test reward</td><td>500.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas lower inner_size</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b0ez5isg' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/b0ez5isg</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_112644-b0ez5isg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a313c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_122017-c6buqnzv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c6buqnzv' target=\"_blank\">ReinforceBas higher lrb</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c6buqnzv' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c6buqnzv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 19.8\n",
      "Average Length: 19.8\n",
      "Running reward: 0.9013606905937195\n",
      "Average Total: 213.3\n",
      "Average Length: 213.3\n",
      "Running reward: 65.07324981689453\n",
      "Average Total: 493.9\n",
      "Average Length: 493.9\n",
      "Running reward: 91.6904525756836\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.04548645019531\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.26725769042969\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.80255889892578\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.128662109375\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 95.4605484008789\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.33232879638672\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.28246307373047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.15731048583984\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 94.3599624633789\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32581329345703\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34928131103516\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 451.5\n",
      "Average Length: 451.5\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.29354858398438\n",
      "Average Total: 452.2\n",
      "Average Length: 452.2\n",
      "Running reward: 98.3455581665039\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34654235839844\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.27521514892578\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:c6buqnzv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▄█████████████▇█▇██</td></tr><tr><td>Average Total Reward</td><td>▁▄█████████████▇█▇██</td></tr><tr><td>Avg_length</td><td>▁▄█████████████▇█▇██</td></tr><tr><td>Avg_total_reward</td><td>▁▄█████████████▇█▇██</td></tr><tr><td>Baseline Loss</td><td>▂▂▄▄▅▄▅▄▄▄▄▃▄▁▇▅▃█▂▃▄▄▃▁▃▁▂▁▂▁▁▁▂▁▁▁▃▅▂▂</td></tr><tr><td>Loss_baseline</td><td>▂▂▄▄▅▄▅▄▄▄▄▃▄▁▇▅▃█▂▃▄▄▃▁▃▁▂▁▂▁▁▁▂▁▁▁▃▅▂▂</td></tr><tr><td>Policy Loss</td><td>▄▆▆█▄▆▅▆▅▅▄▇▅▆▆▅▆▁▆▇▆█▅▆▃▅▆▅▇▆▇▆▇▅▅▅▆▇▇▅</td></tr><tr><td>Reward</td><td>▁▃▆▇█▇█████████████████████████████████▇</td></tr><tr><td>Running Reward</td><td>▁▃▆▇█▇█████████████████████████████████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>24.9475</td></tr><tr><td>Loss_baseline</td><td>24.9475</td></tr><tr><td>Policy Loss</td><td>0.74484</td></tr><tr><td>Reward</td><td>87.66064</td></tr><tr><td>Running Reward</td><td>87.66064</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas higher lrb</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/c6buqnzv' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/c6buqnzv</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_122017-c6buqnzv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:c6buqnzv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_124514-t7g95g5q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/t7g95g5q' target=\"_blank\">ReinforceBas higher lrb</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/t7g95g5q' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/t7g95g5q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 21.8\n",
      "Average Length: 21.8\n",
      "Running reward: 0.6927111744880676\n",
      "Average Total: 85.4\n",
      "Average Length: 85.4\n",
      "Running reward: 45.39704132080078\n",
      "Average Total: 383.9\n",
      "Average Length: 383.9\n",
      "Running reward: 93.3168716430664\n",
      "Average Total: 467.5\n",
      "Average Length: 467.5\n",
      "Running reward: 94.18602752685547\n",
      "Average Total: 483.9\n",
      "Average Length: 483.9\n",
      "Running reward: 95.03372955322266\n",
      "Average Total: 431.0\n",
      "Average Length: 431.0\n",
      "Running reward: 96.9093017578125\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.8935317993164\n",
      "Average Total: 459.1\n",
      "Average Length: 459.1\n",
      "Running reward: 97.66127014160156\n",
      "Average Total: 432.6\n",
      "Average Length: 432.6\n",
      "Running reward: 86.75359344482422\n",
      "Average Total: 493.9\n",
      "Average Length: 493.9\n",
      "Running reward: 92.00419616699219\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.31185913085938\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34847259521484\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34767150878906\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.2796859741211\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.54527282714844\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.06954956054688\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34776306152344\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.5434799194336\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34465789794922\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32923889160156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:t7g95g5q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▆██▇█▇▇███████████</td></tr><tr><td>Average Total Reward</td><td>▁▂▆██▇█▇▇███████████</td></tr><tr><td>Avg_length</td><td>▁▂▆██▇█▇▇███████████</td></tr><tr><td>Avg_total_reward</td><td>▁▂▆██▇█▇▇███████████</td></tr><tr><td>Baseline Loss</td><td>▁▂▄▅▄▃▇▃▃▃▄▆▄▄▂▂▄▆▄▂▃▁▃▂▂▂▂▃▁▁▂▂▁▂█▃▂▁▁▄</td></tr><tr><td>Loss_baseline</td><td>▁▂▄▅▄▃▇▃▃▃▄▆▄▄▂▂▄▆▄▂▃▁▃▂▂▂▂▃▁▁▂▂▁▂█▃▂▁▁▄</td></tr><tr><td>Policy Loss</td><td>▃▄▁▆▆▇▁▃▇▄█▅▄▅▅▄▃▄▅▃▆▅▄▅▅▃▄▃▄▄▄▂▃▅▇▄▆▄▄▅</td></tr><tr><td>Reward</td><td>▁▃▄▆███▇███████▇████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▃▄▆███▇███████▇████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>399.52283</td></tr><tr><td>Loss_baseline</td><td>399.52283</td></tr><tr><td>Policy Loss</td><td>-1.00553</td></tr><tr><td>Reward</td><td>97.75267</td></tr><tr><td>Running Reward</td><td>97.75267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas higher lrb</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/t7g95g5q' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/t7g95g5q</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_124514-t7g95g5q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:t7g95g5q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_130923-ada4nvbb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/ada4nvbb' target=\"_blank\">ReinforceBas higher lrb</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/ada4nvbb' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/ada4nvbb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 22.7\n",
      "Average Length: 22.7\n",
      "Running reward: 1.5372270345687866\n",
      "Average Total: 67.0\n",
      "Average Length: 67.0\n",
      "Running reward: 38.81025695800781\n",
      "Average Total: 168.9\n",
      "Average Length: 168.9\n",
      "Running reward: 77.17304229736328\n",
      "Average Total: 224.1\n",
      "Average Length: 224.1\n",
      "Running reward: 82.11857604980469\n",
      "Average Total: 423.8\n",
      "Average Length: 423.8\n",
      "Running reward: 96.67865753173828\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.27657318115234\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34899139404297\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.03437805175781\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.21302795410156\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.08950805664062\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.31603240966797\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34922790527344\n",
      "Average Total: 437.4\n",
      "Average Length: 437.4\n",
      "Running reward: 96.22920227050781\n",
      "Average Total: 484.7\n",
      "Average Length: 484.7\n",
      "Running reward: 98.11629486083984\n",
      "Average Total: 494.4\n",
      "Average Length: 494.4\n",
      "Running reward: 98.02938842773438\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.61329650878906\n",
      "Average Total: 418.1\n",
      "Average Length: 418.1\n",
      "Running reward: 97.27330780029297\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.32893371582031\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34930419921875\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ada4nvbb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▃▄▇███████▇███▇███</td></tr><tr><td>Average Total Reward</td><td>▁▂▃▄▇███████▇███▇███</td></tr><tr><td>Avg_length</td><td>▁▂▃▄▇███████▇███▇███</td></tr><tr><td>Avg_total_reward</td><td>▁▂▃▄▇███████▇███▇███</td></tr><tr><td>Baseline Loss</td><td>▁▁▁▂▂▃▂▃█▃▃▂▂▁▂▁▁▁▂▃▂▂▁▂▂▃▂▂▃▂▂▂▁▁▁▁▁▂▁▁</td></tr><tr><td>Loss_baseline</td><td>▁▁▁▂▂▃▂▃█▃▃▂▂▁▂▁▁▁▂▃▂▂▁▂▂▃▂▂▃▂▂▂▁▁▁▁▁▂▁▁</td></tr><tr><td>Policy Loss</td><td>▇▆▇█▇▇▆█▁▇▇█▆▇▇▇▆▇▆█▆▇▇▇▇▆█▇▇▇▅▇▇▇▇▇▇▇▆▇</td></tr><tr><td>Reward</td><td>▁▂▃▅▆█▇█████████████████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▃▅▆█▇█████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>500.0</td></tr><tr><td>Average Total Reward</td><td>500.0</td></tr><tr><td>Avg_length</td><td>500.0</td></tr><tr><td>Avg_total_reward</td><td>500.0</td></tr><tr><td>Baseline Loss</td><td>201.73639</td></tr><tr><td>Loss_baseline</td><td>201.73639</td></tr><tr><td>Policy Loss</td><td>1.46595</td></tr><tr><td>Reward</td><td>98.34936</td></tr><tr><td>Running Reward</td><td>98.34936</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas higher lrb</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/ada4nvbb' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/ada4nvbb</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_130923-ada4nvbb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ada4nvbb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_133324-3zewivi4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3zewivi4' target=\"_blank\">ReinforceBas higher lrb</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3zewivi4' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/3zewivi4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 20.3\n",
      "Average Length: 20.3\n",
      "Running reward: 1.1382864713668823\n",
      "Average Total: 125.3\n",
      "Average Length: 125.3\n",
      "Running reward: 58.06493377685547\n",
      "Average Total: 398.3\n",
      "Average Length: 398.3\n",
      "Running reward: 87.54988861083984\n",
      "Average Total: 433.3\n",
      "Average Length: 433.3\n",
      "Running reward: 95.77208709716797\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.10147094726562\n",
      "Average Total: 467.9\n",
      "Average Length: 467.9\n",
      "Running reward: 97.2571792602539\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.1942138671875\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.2298355102539\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.50343322753906\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.25199890136719\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34768676757812\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.89368438720703\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.86255645751953\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.29279327392578\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.19113159179688\n",
      "Average Total: 116.6\n",
      "Average Length: 116.6\n",
      "Running reward: 87.7859878540039\n",
      "Average Total: 263.3\n",
      "Average Length: 263.3\n",
      "Running reward: 94.57848358154297\n",
      "Average Total: 167.7\n",
      "Average Length: 167.7\n",
      "Running reward: 83.57909393310547\n",
      "Average Total: 208.7\n",
      "Average Length: 208.7\n",
      "Running reward: 85.60132598876953\n",
      "Average Total: 473.6\n",
      "Average Length: 473.6\n",
      "Running reward: 94.31341552734375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3zewivi4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▃▇▇███████████▂▅▃▄█</td></tr><tr><td>Average Total Reward</td><td>▁▃▇▇███████████▂▅▃▄█</td></tr><tr><td>Avg_length</td><td>▁▃▇▇███████████▂▅▃▄█</td></tr><tr><td>Avg_total_reward</td><td>▁▃▇▇███████████▂▅▃▄█</td></tr><tr><td>Baseline Loss</td><td>▄▃▃█▅▃▅▁█▄▆▆▆▆▄▁▂▁▁▂▁▂▂▁▂▂▁▁▃▄▄▃▂▂▁▁▆▂▃▂</td></tr><tr><td>Loss_baseline</td><td>▄▃▃█▅▃▅▁█▄▆▆▆▆▄▁▂▁▁▂▁▂▂▁▂▂▁▁▃▄▄▃▂▂▁▁▆▂▃▂</td></tr><tr><td>Policy Loss</td><td>█▅▇▃▆▆▃▅▄▇▂▁▆▆▇▅▆▅▅▄▅▆▅▅▆▄▆▅▃▄▄▆▅▅▄▅▄▆▇▅</td></tr><tr><td>Reward</td><td>▁▃▅▆▇▇██████████████████▇█████▇█▇▇▇▇▇▇██</td></tr><tr><td>Running Reward</td><td>▁▃▅▆▇▇██████████████████▇█████▇█▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>473.6</td></tr><tr><td>Average Total Reward</td><td>473.6</td></tr><tr><td>Avg_length</td><td>473.6</td></tr><tr><td>Avg_total_reward</td><td>473.6</td></tr><tr><td>Baseline Loss</td><td>101.52434</td></tr><tr><td>Loss_baseline</td><td>101.52434</td></tr><tr><td>Policy Loss</td><td>-0.64806</td></tr><tr><td>Reward</td><td>93.21489</td></tr><tr><td>Running Reward</td><td>93.21489</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas higher lrb</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/3zewivi4' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/3zewivi4</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_133324-3zewivi4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3zewivi4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Niccolò\\Desktop\\DLA\\VSCodeLabs\\DLA\\Lab3\\wandb\\run-20240512_135457-b5rsyfws</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b5rsyfws' target=\"_blank\">ReinforceBas higher lrb</a></strong> to <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b5rsyfws' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/b5rsyfws</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent with baseline value network.\n",
      "Average Total: 19.9\n",
      "Average Length: 19.9\n",
      "Running reward: 0.8604653477668762\n",
      "Average Total: 107.1\n",
      "Average Length: 107.1\n",
      "Running reward: 52.112220764160156\n",
      "Average Total: 343.3\n",
      "Average Length: 343.3\n",
      "Running reward: 92.42385864257812\n",
      "Average Total: 270.1\n",
      "Average Length: 270.1\n",
      "Running reward: 93.06834411621094\n",
      "Average Total: 272.7\n",
      "Average Length: 272.7\n",
      "Running reward: 95.0214614868164\n",
      "Average Total: 499.6\n",
      "Average Length: 499.6\n",
      "Running reward: 96.44585418701172\n",
      "Average Total: 497.5\n",
      "Average Length: 497.5\n",
      "Running reward: 97.79147338867188\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 96.88499450683594\n",
      "Average Total: 154.6\n",
      "Average Length: 154.6\n",
      "Running reward: 89.80244445800781\n",
      "Average Total: 487.7\n",
      "Average Length: 487.7\n",
      "Running reward: 95.1417236328125\n",
      "Average Total: 387.5\n",
      "Average Length: 387.5\n",
      "Running reward: 98.17354583740234\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.0136947631836\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34745025634766\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.2496566772461\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34883880615234\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 97.70570373535156\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34558868408203\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 500.0\n",
      "Average Length: 500.0\n",
      "Running reward: 98.34935760498047\n",
      "Average Total: 425.2\n",
      "Average Length: 425.2\n",
      "Running reward: 95.51716613769531\n"
     ]
    }
   ],
   "source": [
    "state_dicts = []\n",
    "for i in range(n_run):\n",
    "\n",
    "    # Instantiate a rendering and a non-rendering environment.\n",
    "    env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    torch.manual_seed(seeds[i])\n",
    "    env_render.reset(seed = val_seeds[i])\n",
    "    env.reset(seed = seeds[i])\n",
    "\n",
    "    run = wandb.init(\n",
    "          # Set the project where this run will be logged\n",
    "          project=\"Lab3-Final\",\n",
    "          # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "          name=f\"ReinforceBas higher lrb\",\n",
    "          # Track hyperparameters and run metadata\n",
    "          config={\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"baaseline_learning_rate\":1e-2,\n",
    "          \"architecture\": \"REINFORCE_BAS\",\n",
    "          \"dataset\": \"CartPole\",\n",
    "          \"hidden_layer_size\": 128,\n",
    "          \"episodes\": 2000,\n",
    "          \"gamma\": 0.99,\n",
    "          \"episode_max_len\": 500,\n",
    "          \"N\": 100,\n",
    "          \"temperature\": 10,\n",
    "          \"M\": 10,\n",
    "          \"baseline\": \"BaselineNet\",\n",
    "          \"learning_rate_baseline\": 0.1})\n",
    "\n",
    "    # Make a policy and a baseline network.\n",
    "    policy = PolicyNet(env, inner_size=run.config[\"hidden_layer_size\"], T=run.config[\"temperature\"])\n",
    "    baseline = BaselineNet(env)\n",
    "\n",
    "    # Train the agent.r = ReinforceBas(policy, env, env_render, num_episodes=2000, baseline=baseline)\n",
    "    r = ReinforceBas(policy, env, env_render, gamma=run.config[\"gamma\"], num_episodes=run.config[\"episodes\"],\n",
    "                  lr=run.config[\"learning_rate\"], max_len=run.config[\"episode_max_len\"],\n",
    "                     N=run.config[\"N\"], eval_episodes=run.config[\"M\"], baseline=baseline,\n",
    "                     lrb=run.config[\"learning_rate_baseline\"])\n",
    "    (total, average, length, state_dict) = r.reinforce()\n",
    "\n",
    "    state_dicts.append(state_dict)\n",
    "\n",
    "    # Close up everything\n",
    "    env_render.close()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0b898df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for episode: 231.95\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 500.0\n",
      "Average reward for episode: 471.4\n",
      "Average reward for episode: 500.0\n",
      "Total Average reward for test episode: 440.66999999999996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>▁▂▆▅▅███▃█▆████████▇</td></tr><tr><td>Average Total Reward</td><td>▁▂▆▅▅███▃█▆████████▇</td></tr><tr><td>Avg_length</td><td>▁▂▆▅▅███▃█▆████████▇</td></tr><tr><td>Avg_total_reward</td><td>▁▂▆▅▅███▃█▆████████▇</td></tr><tr><td>Baseline Loss</td><td>▃▃▇▇▄▄▃█▃▆▃▂▁▁▁▂▁▂▁▁▁▆▁▇▁▂▁▁▂▂▂▂▂▄▃▃▆▃▆▂</td></tr><tr><td>Loss_baseline</td><td>▃▃▇▇▄▄▃█▃▆▃▂▁▁▁▂▁▂▁▁▁▆▁▇▁▂▁▁▂▂▂▂▂▄▃▃▆▃▆▂</td></tr><tr><td>Policy Loss</td><td>▆▆▁▂▄▅▇▁▃█▃▆▅▅▅▃▄▆▄▅▅█▅▅▅▇▆▅▄▅▅▅▃▅▅▄▂▆▅▅</td></tr><tr><td>Reward</td><td>▁▂▅▇████████████▇▇██████████████████████</td></tr><tr><td>Running Reward</td><td>▁▂▅▇████████████▇▇██████████████████████</td></tr><tr><td>Total average test reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Length</td><td>425.2</td></tr><tr><td>Average Total Reward</td><td>425.2</td></tr><tr><td>Avg_length</td><td>425.2</td></tr><tr><td>Avg_total_reward</td><td>425.2</td></tr><tr><td>Baseline Loss</td><td>92.30949</td></tr><tr><td>Loss_baseline</td><td>92.30949</td></tr><tr><td>Policy Loss</td><td>-0.81379</td></tr><tr><td>Reward</td><td>98.30076</td></tr><tr><td>Running Reward</td><td>98.30076</td></tr><tr><td>Total average test reward</td><td>440.67</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReinforceBas higher lrb</strong> at: <a href='https://wandb.ai/dla-labs/Lab3-Final/runs/b5rsyfws' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final/runs/b5rsyfws</a><br/> View project at: <a href='https://wandb.ai/dla-labs/Lab3-Final' target=\"_blank\">https://wandb.ai/dla-labs/Lab3-Final</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240512_135457-b5rsyfws\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And run the final agent for a few episodes.\n",
    "env_render = gym.make('CartPole-v1', render_mode='human')\n",
    "env_render.reset(seed = 100)\n",
    "r.setEnvRender(env_render)\n",
    "\n",
    "average_test_rewards = []\n",
    "for state_dict in state_dicts:\n",
    "    total_rewards = 0\n",
    "    policy = PolicyNet(env = env_render)\n",
    "    policy.load_state_dict(state_dict)\n",
    "    r.setPolicy(policy)\n",
    "    for _ in range(20):\n",
    "        (_, _, _, rewards, _, _) = r.run_episode(display=True, test=True)\n",
    "        total_rewards += np.sum(rewards)\n",
    "    average_test_reward = total_rewards / 20\n",
    "    print(f'Average reward for episode: {average_test_reward}')\n",
    "    average_test_rewards.append(average_test_reward)\n",
    "avg_test_rew = np.sum(average_test_rewards) / 5\n",
    "print(f'Total Average reward for test episode: {avg_test_rew}')\n",
    "test_metrics = {\"Total average test reward\": avg_test_rew}\n",
    "wandb.log({**test_metrics})\n",
    "env_render.close()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf1447-d222-4b24-a357-5b7f9824390c",
   "metadata": {
    "id": "64bf1447-d222-4b24-a357-5b7f9824390c"
   },
   "source": [
    "-----\n",
    "## Exercise 3: Going Deeper\n",
    "\n",
    "As usual, pick **AT LEAST ONE** of the following exercises to complete.\n",
    "\n",
    "### Exercise 3.1: Solving Lunar Lander with `REINFORCE` (easy)\n",
    "\n",
    "Use my (or even better, improve on my) implementation of `REINFORCE` to solve the [Lunar Lander Environment](https://gymnasium.farama.org/environments/box2d/lunar_lander/). This environment is a little bit harder than Cartpole, but not much. Make sure you perform the same types of analyses we did during the lab session to quantify and qualify the performance of your agents.\n",
    "\n",
    "### Exercise 3.2: Solving Cartpole and Lunar Lander with `Deep Q-Learning` (harder)\n",
    "\n",
    "On policy Deep Reinforcement Learning tends to be **very unstable**. Write an implementation (or adapt an existing one) of `Deep Q-Learning` to solve our two environments (Cartpole and Lunar Lander). To do this you will need to implement a **Replay Buffer** and use a second, slow-moving **target Q-Network** to stabilize learning.\n",
    "\n",
    "### Exercise 3.3: Solving the OpenAI CarRacing environment (hardest)\n",
    "\n",
    "Use `Deep Q-Learning` -- or even better, an off-the-shelf implementation of **Proximal Policy Optimization (PPO)** -- to train an agent to solve the [OpenAI CarRacing](https://github.com/andywu0913/OpenAI-GYM-CarRacing-DQN) environment. This will be the most *fun*, but also the most *difficult*. Some tips:\n",
    "\n",
    "1. Make sure you use the `continuous=False` argument to the environment constructor. This ensures that the action space is **discrete** (we haven't seen how to work with continuous action spaces).\n",
    "2. Your Q-Network will need to be a CNN. A simple one should do, with two convolutional + maxpool layers, folowed by a two dense layers. You will **definitely** want to use a GPU to train your agents.\n",
    "3. The observation space of the environment is a single **color image** (a single frame of the game). Most implementations stack multiple frames (e.g. 3) after converting them to grayscale images as an observation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
